---
calendar_date: 2021-12-15
catalog: true
categories:
- Pytorch
cover:
  image: /cover/cover7.jpeg
date: 2021-12-15 08:00:57
description: Basic Knowledge of PyTorch
lang: cn
mathjax: false
tags:
- Pytorch
thumbnail: /img/header_img/lml_bg7.jpg
title: PyTorch Handbook 00 ï¼ˆArchiveï¼‰
toc: true
---

# Basic PartåŸºç¡€è®¾å®šéƒ¨åˆ†

@AikenH 2020 + 2021

this part is about pytorch basic unit, help me to code deep learning better.

## Tensorå¼ é‡è®¡ç®—

### ä¸¤ä¸ªtensorçš„æ•°ä¹˜


è®¡ç®—ä¸¤ä¸ªtensorçš„çŸ©é˜µä¹˜æ³•ï¼Œæ³¨æ„å…¶ä¸­çš„batchè¦ç›¸äº’å¯¹åº”ï¼Œå¦‚æœä¸è€ƒè™‘batchï¼Œå°±æ˜¯å¦ä¸€ä¸ªå‡½æ•°

```python
# ç®€å•çš„åˆ†æä¸€ä¸‹ç®—æ³•çš„é€»è¾‘
# è¿™æ˜¯å‰²è£‚å‡ºæ¥batchçš„çŸ©é˜µç›¸ä¹˜å½¢å¼
batch1 = torch.randn(10,3,4)
batch2 = torch.randn(10,4,5)
out = torch.bmm(batch1, batch2)
out.size()

'''output ans is
torch.size([10,3,5])'''

# æŒ‰ä½ç›¸ä¹˜
res = torch.mul(batch1,batch2)
```

**viewå’Œpermute**çš„ä½¿ç”¨å®é™…ä¸Šéƒ½æ˜¯ä¸æ”¹å˜åŸå€¼ï¼Œè¦ç”¨èµ‹å€¼çš„æ–¹å¼å»åšï¼Œä¸»è¦æ˜¯ä½¿ç”¨æ–¹å¼è¦å¯¹ï¼Œä¸€ä¸ªæ˜¯æŒ‰ç…§é¡ºåºå»åšã€‚

### å¼ é‡å‘½å

```python
NCHW = [â€˜Nâ€™, â€˜Câ€™, â€˜Hâ€™, â€˜Wâ€™]
images = torch.randn(32, 3, 56, 56, names=NCHW)
images.sum('C')
images.select('C', index=0)
```

### ç±»å‹è½¬æ¢

```python
# tensor ä¸ nd.arrayè¿›è¡Œäº’æ¢
ndarray = tensor.cpu().numpy()
tensor = torch.from_numpy(ndarray).float()

# tensorä¸PIL.IMAGEè¿›è¡Œäº’æ¢
image = torchvision.transforms.functional.to_pil_image(tensor)
path = r'./figure.jpg'
tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))

# np.ndarray ä¸ PIL.Imageçš„äº’æ¢
image = PIL.Image.fromarray(nd.array.astype(np.uint8))
ndarray = np.asarray(PIL.Image.open(path))
```

### ç»´åº¦å †å 

Stackï¼Œ**æ™®é€šçš„ç»´åº¦å †å çš„æµ‹è¯•ä»£ç å¦‚ä¸‹**

æµ‹è¯•ä»£ç å¦‚ä¸‹ï¼Œå®é™…ä¸Šdim=0å°±æ˜¯åŸºæœ¬çš„å †èµ·æ¥ï¼Œdim=1å°±æ˜¯æŒ‰ç…§è¡Œæ¥å †ï¼Œdim=2å°±æ˜¯æŒ‰ç…§åˆ—æ¥å †

```python
a = torch.arange(1,10).reshape(3,3)
b = torch.arange(10,100,10).reshape(3,3)
c = torch.arange(100,1000,100).reshape(3,3)
print('-----------------a----------------')
print(a)
print('-----------------b----------------')
print(b)
print('-----------------c----------------')
print(c)
print('-----------------dim =0----------------')
d = torch.stack((a,b,c),dim = 0)
print(d.shape)
print('the value of d:-    {}'.format(d[2,1,0]))
print(d)
# ä¹Ÿå°±æ˜¯è¯´ï¼ŒæŠŠå•ä¸ªå½“æˆæ•´ä½“ç›´æ¥ä»ä¸Šå¾€ä¸‹å †å 
# ä»¥x[:][:]ä¸ºæ„æˆå•å…ƒ
print('-----------------dim =1----------------')
d = torch.stack((a,b,c),dim = 1)
print(d.shape)
print('the value of d:-    {}'.format(d[1,2,2]))
print(d)
# å°†æ¯ä¸ªçš„ç¬¬ä¸€ä¸ªç»´åº¦ï¼ŒæŒ‰æ¬¡åºçº³å‡ºæ¥ï¼ŒåŒvalueçš„å †åœ¨ä¸€èµ·
# for exampleï¼š[a[i][:],b[i][:],c[i][:] ]ç»„æˆæ–°çš„å•å…ƒå—
# ä¸ï¼Œå¦ä¸€ç§ç†è§£ï¼Œä»¥x[i][:] ä¸ºå•å…ƒ
print('-----------------dim =2----------------')
d = torch.stack((a,b,c),dim = 2)
print(d.shape)
print('the value of d:-    {}'.format(d[1,2,1]))
print(d)
# ç›¸åº”çš„ä»¥x[i][j]ä¸ºå•å…ƒæ„æˆ
```

**listçš„æƒ…å†µä¸‹çš„ç»´åº¦å †å æµ‹è¯•ä»£ç å¦‚ä¸‹**

ç›¸åº”çš„æµ‹è¯•ä»£ç å¦‚ä¸‹ï¼Œå®é™…ä¸Šä¸€èˆ¬æ˜¯æŒ‰ç…§dim=1æ¥è¿›è¡Œå †å 

```python
A = torch.randn([3,4,2])
B = [A[:,i] for i in range(A.size(1))]
# è¿™æ ·ç”Ÿæˆçš„æ˜¯ä¸€ä¸ªlist,æŒ‰ç…§æˆ‘ä»¬indexçš„æ’åº
print(A)
print(B)
C = torch.stack(B,dim=1)
print('---------------------result-----------------------')
print(C)
```

**Cat**

å®é™…ä¸Šåº”è¯¥ä¹Ÿæ˜¯ç±»ä¼¼çš„å †å æ€è·¯

## åŸºæœ¬çš„å¼ é‡å‡½æ•°

torch.split() åˆ’åˆ†tensor

torch.randpermè¿›è¡Œlistçš„ä¹±åºå¤„ç†

```python
# å’ŒshuffleåŒºåˆ†ï¼Œè¿™æ˜¯å¦ä¸€ç§ä¹±åºçš„æ“ä½œ
# catæ“ä½œ
a = []
for i in range(3):
    a.append(torch.tensor([i,i]))
all_inputs = torch.cat(a)
# randpermçš„æ•ˆæœ test1
idx = torch.randperm(all_inputs.size(0))
print(idx)
a1, b = all_inputs, all_inputs[idx]
print(a1,b)
# test2 ï¼Œ
print('-------------------------')
# randperm è¿›è¡Œlistçš„shuffle
tensor_a = torch.randint(0,10,[8])
print('origin version ', tensor_a)
idx = torch.randperm(tensor_a.size(0))
print('shuffle idx ', idx)
tensor_b = tensor_a[idx]
print('after operation ', tensor_b)
```

.fill_()æŒ‰ç…§è¾“å…¥çš„å€¼å¯¹å¼ é‡è¿›è¡Œå¡«å……

### é€‰å–åˆ’çª—

`nn.unfold`æ‹†è§£å·ç§¯ä¸­çš„åˆ’çª—æ­¥éª¤

```python
import torch
inputs = torch.randn(1,3,224,224)
unfold = torch.nn.Unfold(4,stride=4)
output = unfold(inputs)
# res output
output.size()
$ [1,4,3136]
# 3136 = (224/4) * (224/4)
```



## Torchç¯å¢ƒè®¾ç½®

### pytorchä¸­çš„éšæœºç§å­åˆå§‹åŒ–

yTorch å’Œ Pythonçš„éšæœºæ•°ç”Ÿæˆå™¨å°±ç®—éšæœºç§å­ä¸€æ ·ä¹Ÿä¸ä¼šäº§ç”Ÿä¸€æ ·çš„ç»“æœã€‚

æˆ‘ä»¬å¯ä»¥è¿™æ ·æ¥è®¾ç½®Pytorchçš„éšæœºæ•°ç§å­ï¼šï¼ˆé€šå¸¸å’ŒGPUä¸€èµ·ä½¿ç”¨ï¼‰

```python
torch.manual_seed(seed)

```

### nn.parameter()

1. Main ideaï¼š**parameterçš„ä½œç”¨ï¼Œä¸»è¦æ˜¯å°†å‚æ•°å’Œmodelç»‘å®šåœ¨ä¸€èµ·**ï¼Œæˆ‘ä»¬å°±çŸ¥é“è¿™ä¸ªæ¨¡å‹ä¸­ï¼Œå¯èƒ½éœ€**è¦è®­ç»ƒçš„å‚æ•°**æœ‰å“ªäº›ï¼Œå¯ä»¥éœ€è¦è¿›è¡Œè®­ç»ƒçš„å‚æ•°åŠ è¿›å»ï¼Œä½†æ˜¯å½“æˆ‘ä»¬æƒ³è¦freeze itçš„æ—¶å€™å°±ä½¿ç”¨detachæˆ–è€…ç›´æ¥ä¿®æ”¹require_gradæ¥è®©å‚æ•°ä¸åœ¨æ¥å—è®­ç»ƒå°±å¥½äº†ï¼Œ require_gradæ˜¯å…¶ä¸­çš„ä¸€ä¸ªå±æ€§ã€‚å¯ä»¥ç»“åˆä¸Šé¢çš„ä»£ç åˆ†æã€‚
2. tensorå˜é‡æ˜¯ä¸å¯è®­ç»ƒçš„ï¼Œåªæœ‰ä¿®æ”¹æˆparameteræ‰èƒ½è¿›è¡Œè®­ç»ƒã€‚
3. è‡ªå¸¦çš„ç½‘ç»œç»“æ„ä¸­çš„ä¸€äº›weightå’Œbiasåº”è¯¥éƒ½æ˜¯parameterçš„å˜é‡

### nn.Softmaxä¸­çš„dim

å…¶å®æ²¡é‚£ä¹ˆå¤æ‚ï¼Œå°±å’Œæ•°æ®çš„ç»´åº¦æ˜¯ä¸€æ ·çš„ï¼Œæˆ‘ä»¬éœ€è¦æŠŠé‚£ä¸€ä¸ªç»´åº¦çš„æ•°æ®ä¹‹åçš„æ•°æ®å…¨éƒ¨åŠ èµ·æ¥å¤„ç†å°±ç”¨å“ªä¸ªç»´åº¦å»åšã€‚

IMAGE = N* DATAï¼Œdim=1 è¯´æ˜dim = 0 çš„Channel æ˜¯éœ€è¦è¢«æ’å¤–çš„ã€‚ä¹Ÿå°±æ˜¯æˆ‘ä»¬çš„softmaxæ˜¯åŸºäºdataè¿›è¡Œçš„ã€‚å¯ä»¥æ‰¾å¯»æºç è¿›è¡Œè¿›ä¸€æ­¥åˆ†æè§£é‡Šã€‚

## æµ‹è¯•ã€éªŒè¯æ¨¡å—

### åŸºæœ¬ç¼–å†™

### model.eval()å’Œmodel.train()çš„åŒºåˆ«

é€šå¸¸åœ¨æ¨¡å‹æµ‹è¯•çš„æ—¶å€™ä¼šæ‰§è¡Œ`model.eval()`åˆ‡æ¢æ¨¡å‹çš„çŠ¶æ€ï¼Œè€Œåœ¨è®­ç»ƒçš„æ—¶å€™ä¼šæ‰§è¡Œ`model.train()`ï¼Œmodelåœ¨è¿™ä¸¤ä¸ªçŠ¶æ€ä¸‹çš„åŒºåˆ«ä¸»è¦æœ‰ï¼š

åœ¨**train**çŠ¶æ€ä¸‹ä¼šå¯ç”¨BNå’ŒDropoutï¼Œè€Œåœ¨**eval**ä¸å¯ç”¨è¿™ä¸¤ä¸ªæ¨¡å—ï¼›

- å¯ç”¨BNæŒ‡çš„æ˜¯ï¼šç”¨åˆ°æ¯ä¸€ä¸ªBatchæ•°æ®çš„å‡å€¼å’Œæ–¹å·®ï¼›ä¸å¯ç”¨åˆ™æŒ‡çš„æ˜¯ä½¿ç”¨æ•´ä½“çš„å‡å€¼å’Œæ–¹å·®ï¼ˆåŒæ—¶åœæ­¢æ›´æ–°meanå’Œvarï¼‰
- è€Œå¯¹äºDropoutæ¥è¯´ï¼šå¯ç”¨çš„æ—¶å€™æŒ‡çš„æ˜¯ä¼šéšæœºè¿›è¡Œdropoutï¼Œè€Œå…³é—­çš„è¯å°±ä¼šç”¨åˆ°å…¨éƒ¨çš„ç½‘ç»œé“¾æ¥

### with torch.no_grad()

ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œwrapèµ·æ¥çš„éƒ¨åˆ†ä¸ä¼štrack grade

ä¸»è¦ç”¨äºåœæ­¢autogradæ¨¡å—çš„å·¥ä½œï¼Œè¢«`with`åŒ…è£¹èµ·æ¥çš„éƒ¨åˆ†ä¼šåœæ­¢æ¢¯åº¦çš„æ›´æ–°ï¼Œå¾—åˆ°è¿›ä¸€æ­¥çš„åŠ é€ŸæŠŠï¼Œå› ä¸ºæˆ‘ä»¬å®é™…ä¸Šåœ¨éªŒè¯çš„æ—¶å€™ä¸ä¼šæ‰§è¡Œ`step()`ç­‰æ“ä½œï¼Œæ‰€ä»¥èƒ½å¤ŸèŠ‚çœè®¡ç®—æ¨¡å‹æ¢¯åº¦çš„æ—¶é—´ã€‚

### æ¨¡å‹çš„ä¿å­˜å’Œè¯»å–ä¸“é¢˜

@Aiken 2020

åŸºäºonenoteç¬”è®°ï¼Œæˆ‘ä»¬çŸ¥é“å…³é”®åœ¨äºå¦‚ä½•è‡ªç”±çš„è¯»å–æ¨¡å‹ä¸­çš„å‚æ•°ï¼Œå¹¶é€‰æ‹©æ€§çš„å–å‡ºæ¥ã€‚

[pytorch æ¨¡å‹éƒ¨åˆ†å‚æ•°çš„åŠ è½½_LXX516çš„åšå®¢-CSDNåšå®¢_pytorch åŠ è½½éƒ¨åˆ†å‚æ•°](https://blog.csdn.net/LXX516/article/details/80124768)

```python

# è‡³å°‘åŸºäºè¿™æ ·çš„æ–¹å¼æˆ‘ä»¬èƒ½æŠŠæ¨¡å‹ä¸­å‚æ•°çš„stringå–å‡ºæ¥ã€‚
pretrained_dict=torch.load(model_weight)
model_dict=myNet.state_dict()

# 1. filter out unnecessary keys
pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}

# 2. overwrite entries in the existing state dict
model_dict.update(pretrained_dict)
myNet.load_state_dict(model_dict)

```

# GPUç›¸å…³çš„è®¾ç½®

@written by Aiken, 2020  this document is about Pytorchâ€˜s CUDA, & GPU setting.

## æŸ¥çœ‹GPUçŠ¶æ€

### è®¾ç½®é»˜è®¤GPUè®¾å¤‡

ä¸€èˆ¬ä½¿ç”¨GPUä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“ç³»ç»Ÿä¸­æœ‰å¤šå°‘GPUè®¾å¤‡ï¼Œå› ä¸ºé»˜è®¤çš„GPUè®¾å¤‡æ˜¯0ï¼Œè€Œä¸”ï¼Œå¤§å®¶ä¸€èˆ¬éƒ½ç›´æ¥ä½¿ç”¨è¿™å¼ å¡ï¼Œæ‰€ä»¥æˆ‘ä»¬å¦‚æœåªä½¿ç”¨å•å¡çš„è¯ï¼Œåˆ‡æ¢ä¸€ä¸‹é»˜è®¤çš„GPUè®¾å¤‡ï¼Œèƒ½å¤Ÿé¿å…ä¸€å®šçš„å†²çªã€‚

```bash
# æŸ¥çœ‹GPUä½¿ç”¨çŠ¶æ€
$ nvidia-smi
# or
$ gpustat [--watch]

```

### **è®¾å¤‡åŸºæœ¬ä¿¡æ¯**

1. æŸ¥çœ‹æ˜¯å¦å­˜åœ¨GPUï¼Œæ•°é‡ï¼Œç±»å‹

    ```python
    import torch
    # æŸ¥çœ‹æ˜¯å¦å­˜åœ¨GPUï¼Œæ•°é‡ï¼Œç±»å‹
    torch.cuda.is_available()
    torch.cuda.device_count()
    torch.cuda.get_device_name(0)
    ```

2. æŸ¥çœ‹æŒ‡å®šçš„GPUçš„å®¹é‡å’Œåç§°

    ```python
    torch.cuda.get_device_capability(device)
    torch.cuda.get_device_name(device)
    ```

3. è®¾ç½®å½“å‰ç³»ç»Ÿçš„é»˜è®¤gpu_devicesï¼Œæ¨èä½¿ç”¨osæ¥è®¾ç½®ï¼ˆå®é™…ä¸Šæ˜¯å‘½ä»¤è¡Œä¸­çš„æ“ä½œï¼‰å®é™…ä¸Šæ˜¯ç³»ç»Ÿè®¾å®šé’ˆå¯¹å½“å‰è¿›ç¨‹çš„å¯è§GPUï¼Œå…¶ä»–çš„GPUä¼šå¯¹å½“å‰çš„ç¨‹åºéšè—ï¼Œæ‰€ä»¥é»˜è®¤çš„0

    ```python
    os.environ['CUDA_VISIBLE_DEVICES'] = "id" #æ¨èç”¨æ³•
    # å¯ä»¥åœ¨vscodeçš„launch.jsonä¸­è®¾ç½®env
    ```

    **æ³¨æ„äº‹é¡¹ï¼šè¯¥å‘½ä»¤éœ€è¦åœ¨æ‰€æœ‰è°ƒç”¨äº†CUDAçš„ä»£ç ã€å­ç¨‹åºä¹‹å‰ï¼ŒåŒ…æ‹¬`import`ï¼Œæ‰€ä»¥å¾ˆå¤šä»£ç çš„importéƒ½æ˜¯åœ¨main()ä¸­çš„ã€‚**

## GPUä½¿ç”¨ç‡ä¼˜åŒ–ï¼ˆæ³¨æ„äº‹é¡¹ï¼‰

### ç¼“å­˜çˆ†ç‚¸é—®é¢˜

GPUä½¿ç”¨é€”ä¸­éœ€è¦æ³¨æ„çš„åœ°æ–¹ï¼Œåœ¨æ¯æ¬¡iterationä¹‹åè®°å¾—**æ¸…é™¤åœ¨GPUä¸­å ç”¨**çš„memoryï¼Œcacheç­‰ï¼Œä¸ç„¶æœ‰æ—¶å€™ä¼šå¯¼è‡´ç¼“å­˜å’Œå†…å­˜çš„é€’å¢å’Œçˆ†ç‚¸ã€‚

å…·ä½“æ“ä½œï¼š

```python
torch.cuda.empty_cache()
# after every iteration

```

### è¿è¡Œæ•ˆç‡ä¼˜åŒ–

`cudnn.benchmark`ã€[pytorchè®ºå›](https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936) [pytorchä¸­æ–‡ç½‘](https://www.pytorchtutorial.com/when-should-we-set-cudnn-benchmark-to-true/)ã€[zhihuç©¶æåˆ†ææ–‡](https://zhuanlan.zhihu.com/p/73711222)

**åŸºæœ¬ä½¿ç”¨æ€è·¯**ï¼š

åœ¨ç¨‹åºçš„å¼€å§‹ï¼Œè®©cudnnèŠ±è´¹ä¸€ç‚¹é¢å¤–çš„æ—¶é—´ï¼Œæ‰¾åˆ°é€‚ç”¨äºå½“å‰é…ç½®çš„æœ€ä½³ç®—æ³•ï¼Œä»è€Œä¼˜åŒ–è¿è¡Œæ•ˆç‡ã€‚

**æ³¨æ„äº‹é¡¹ï¼š**

ä½†æ˜¯å¦‚æœæˆ‘ä»¬çš„input_sizeåœ¨æ¯ä¸ªiterationéƒ½å­˜åœ¨å˜åŒ–çš„è¯ï¼Œé‚£ä¹ˆæ¯ä¸€ä¸ªiterationéƒ½è¦æ‰§è¡Œä¸€æ¬¡æœç´¢ï¼Œåè€Œå¾—ä¸å¿å¤±ã€‚

**å…·ä½“æ“ä½œ**

```python
torch.backends.cudnn.benchmark = true
```

### è®¾ç½®ä½¿ç”¨GPUçš„æ–¹å¼

### è®¾ç½®ç›¸åº”çš„éšæœºç§å­

```python
torch.cuda.empty_cache()
# part2 è®¾ç½®éšæœºç§å­
torch.cuda.manual_seed(seed)
torch.cuda.manual_seed_all(seed)

```

### CUDAè½¬æ¢

ä½¿ç”¨`.cuda()`æ¥å¯¹`æ¨¡å‹`ï¼Œ`æ•°æ®`ï¼Œ`Loss`è¿›è¡Œèµ‹å€¼ï¼Œæˆ–è€…ä½¿ç”¨`to_devices()`æ¥è®¾ç½®åˆ°ç›¸åº”çš„GPUè®¾å¤‡

å°†æ¨¡å‹è½¬åŒ–åˆ°cudaä¸­è¦åœ¨ä¼˜åŒ–å™¨çš„å»ºç«‹ä¹‹å‰æ‰§è¡Œï¼Œå› ä¸ºoptimizeræ˜¯å¯¹äºæ¨¡å‹å»ºç«‹çš„ï¼Œå¯¹æ¨¡å‹æ‰§è¡Œcudaåå·²ç»å’ŒåŸæœ¬çš„å‚æ•°å’Œæ¨¡å‹éƒ½ä¸æ˜¯åŒä¸€ä¸ªäº†ï¼Œæ‰€ä»¥ä¸€å®š**è¦åœ¨å»ºç«‹ä¼˜åŒ–å™¨ä¹‹å‰å°±å¯¹æ¨¡å‹è¿›è¡ŒCuda çš„è½¬åŒ–**ã€‚

æ˜¯å¦è¦å¯¹lossè½¬æ¢åˆ°CUDAï¼Œå–å†³äºä¸€ä¸‹çš„ä¸¤ç§æƒ…å†µï¼š

- æŸå¤±å‡½æ•°æ˜¯Functionalï¼šè¿™æ ·çš„è¯åªè¦ä¼ å…¥çš„å‚æ•°æ˜¯CUDAçš„å°±ä¼šå†CUDAä¸Šè®¡ç®—
- æŸå¤±å‡½æ•°æ˜¯Class with paramsï¼šå¦‚æœç±»å†…æœ‰å‚æ•°çš„è¯ï¼Œä¹Ÿè¦è½¬æ¢åˆ°CUDAæ‰èƒ½ä¸€èµ·åœ¨CUDAä¸Šè®¡ç®—


```python
if torch.cuda.is_available():
	try:
		loss = loss.cuda()
	except AttributeError:
		print('the loss is not cuda-able {}'.format(type(loss)))
```
### å¤šGPUå¹¶è¡Œ

ä¸»è¦ä½¿ç”¨çš„å‘½ä»¤`nn.DataParallel()`

```python
model = nn.DataParaller(model,device_ids=None)
# å¦‚æœä¸è®¾å®šidçš„è¯ï¼Œåº”è¯¥æ˜¯è‡ªåŠ¨æŒ‡å®šå…¨éƒ¨å¯è§çš„GPUçš„

```

# CPU

å¶ç„¶ä¼šç”±äº`pin_memory` çš„è®¾ç½®æ¥è‡´ä½¿CPUçš„ä¸æ­£å¸¸è¿è¡Œï¼ˆæ»¡è½½ç­‰ç­‰ï¼‰ï¼Œå¹¶éæ€»æ˜¯è¿™æ ·ã€‚

## æ ¸å¿ƒå’Œçº¿ç¨‹æ•°è®¾ç½®

[é™åˆ¶æˆ–å¢åŠ pytorchçš„çº¿ç¨‹ä¸ªæ•°ï¼æŒ‡å®šæ ¸æ•°æˆ–è€…æ»¡æ ¸è¿è¡ŒPytorchï¼ï¼ï¼_lei_qiçš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/lei_qi/article/details/115358703)

```python
import os
from multiprocessing import cpu_count
# è®¾ç½®ç¯å¢ƒå˜é‡æ¥æ§åˆ¶çº¿ç¨‹å¤šå‘çš„æƒ…å†µ
cpu_num = cpu_count()
# æ ¸å¿ƒä»£ç 
os.environ['OMP_NUM_THREADS'] = str(cpu_num)
# ä¸‹é¢è¿™äº›åº”è¯¥æ˜¯ä¸ä¸€å®šè¯æœ‰
os.environ ['OPENBLAS_NUM_THREADS'] = str(cpu_num)
os.environ ['MKL_NUM_THREADS'] = str(cpu_num)
os.environ ['VECLIB_MAXIMUM_THREADS'] = str(cpu_num)
os.environ ['NUMEXPR_NUM_THREADS'] = str(cpu_num)

# ä»å…¶ä»–èµ„æ–™ä¸­å¯ä»¥æ„Ÿè§‰è¿™æ¡ä»£ç åº”è¯¥æ˜¯å’Œæ ¸å¿ƒä»£ç ä¸€æ ·çš„åŠŸèƒ½ï¼Œæ‰€ä»¥ä¸¤ä¸ªå†™ä¸€ä¸ªåº”è¯¥å°±å¯ä»¥äº†
torch.set_num_threds(cpu_num)
```

# ç½‘ç»œå®šä¹‰æ¨¡å—

## æ•°æ®å®šä¹‰æ¨¡å—
### åˆ©ç”¨TorchVisionè¯»å–æœ¬åœ°æ•°æ®

`torchvision.datasets.imagefolder()` è¿™ä¸ªå‡½æ•°å®é™…ä¸Šèƒ½ä»£æ›¿æˆ‘ä»¬ä¹‹å‰å†™çš„å‡½æ•°ï¼Œä½†æ˜¯ç”±äºè‡ªå·±å†™çš„æœ‰ä¸€éƒ¨åˆ†ç»Ÿä¸€è§„åˆ™å¯ä»¥ä½¿å¾—æˆ‘ä»¬çš„è‡ªå®šä¹‰ç¨‹åº¦å¾ˆé«˜ï¼Œæ‰€ä»¥ç›®å‰æˆ‘ä»¬åœ¨ç»å¤§å¤šæ•°æƒ…å†µä¸‹ä¸ä½¿ç”¨è¯¥æ–¹æ³•æ¥è¿›è¡Œæ›¿ä»£ã€‚

ä½†æ˜¯ç”±äºæ˜¯ä¸€ä¸ªé‡è¦çš„å‡½æ•°ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œè¿˜æ˜¯ä»‹ç»ä¸€ä¸‹è¯¥å·¥å…·çš„ä½¿ç”¨æ–¹å¼ï¼š



### torch è‡ªå®šä¹‰Datasetåçš„ä½¿ç”¨

1. è‡ªå®šä¹‰datasetçš„ç»§æ‰¿ä»¥åŠåç»­è°ƒç”¨éœ€è¦æ³¨æ„çš„æ˜¯ä¸èƒ½å¿˜è®°å°†å…¶è½¬æ¢æˆdataloaerï¼Œç„¶åè¿›è¡Œiterå‘½ä»¤çš„æ‰§è¡Œã€‚
2. ä¹Ÿå¯ä»¥ç”¨enumerateå‡½æ•°æ¥è¿›è¡Œè°ƒç”¨ï¼Œå°±æ˜¯è®°å¾—è°ƒç”¨çš„æ ¼å¼æ˜¯ä»€ä¹ˆå°±å¥½
3. å¯ä»¥å‚è€ƒbasicunitä¸­çš„å¯¹shuffleçš„è®¤çŸ¥å¯¹è¯¥å‡½æ•°è¿›è¡Œè¿›ä¸€æ­¥çš„ç†è§£ã€‚

```python
# å®šä¹‰datasetçš„éƒ¨åˆ†
class RL_AET_Dataset(torch.utils.data.Dataset):
    def __init__(self):
        super(RL_AET_Dataset,self).__init__()
        pass
    def __len__(self):
        pass
    def __getitem(self):
        pass
# å£°æ˜å’Œæ„å»ºéƒ¨åˆ† è¦è®°å¾—ä½¿ç”¨dataloader
train_l_dataset = RL_AET_Dataset(x_l, y_l, args)
train_l_dataloader =torch.utils.data.DataLoader(train_l_dataset,batch_size=args['b_s'],shuffle=True,num_workers=args['num_workers'],drop_last=True,pin_memory=True)

#è°ƒç”¨è¿­ä»£éƒ¨åˆ†
labeled_loader = iter(train_l_dataloader)
#all_label_info =  [*next(labeled_loader)]

```

### Dataloaderä¸­çš„transformerï¼ˆï¼‰ï¼š

**ç–‘æƒ‘è§£ç­”  ç”¨composeé›†æˆçš„æ‰€æœ‰transformï¼Œéƒ½ä¼šåº”ç”¨ï¼Œæœ‰ä¸ªto_tensorï¼Œåˆ‡to_tensorä¼šè‡ªåŠ¨è½¬æ¢PILä¸­çš„channelå’Œæ•°å€¼èŒƒå›´ã€‚**

1. composeä¸­çš„å˜æ¢ç»„åˆçš„é¡ºåºå…³ç³»
    - PILå¤„ç†çš„å›¾åƒå˜æ¢ï¼ˆæ¯”å¦‚æ•°æ®å¢å¼ºä¹‹ç±»çš„æ–¹æ³•ï¼‰
    - `to_tensor()`
    - å¤„ç†tensorçš„æ–¹æ³•ï¼š`normalize`
2. ç¤ºä¾‹ä»£ç 

    ```python
    data_transforms = transforms.Compose([
                            transforms.RandomResizedCrop(224),
                            transforms.RandomHorizontalFlip().
                            transforms.ToTensor(),
                            transforms.Normalize([a,b,c],[A,B,C])])
    # ç„¶åç›´æ¥åŠ å…¥datasetä¸­çš„å‚æ•°ï¼Œæˆ–è€…æ˜¯æˆ‘ä»¬è‡ªå®šä¹‰çš„éƒ¨åˆ†
    # åœ¨datasetä¸­çš„å†™æ³•å¦‚ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è‡ªå·±çš„datasetä¸­è¿›è¡Œå®šä¹‰
    if self.transformer is not None:
            img = self.transform(img)
    # å…·ä½“çš„æºç ç»†èŠ‚è¡¨ç°å¦‚ä¸‹
    for t in self.transforms:
            img = t(img)
    return img
    ```

### Dataloaderä¸­çš„å‚æ•°

shuffleæœºåˆ¶

ä¸»è¦è§£å†³é—®é¢˜ï¼š

1. æ˜¯å¦æ¯æ¬¡è°ƒç”¨çš„æ—¶å€™éƒ½è¿›è¡Œéšæœºçš„æ“ä½œï¼Œè¿˜æ˜¯åªæœ‰åœ¨åˆå§‹åŒ–çš„æ—¶å€™æ‰è¿›è¡Œéšæœº
2. ä¸¤ç§ä¸åŒä½¿ç”¨Dataloaderçš„æ–¹å¼æ˜¯å¦ä¼šå¯¹shuffleçš„æ–¹å¼è¿›è¡ŒåŒºåˆ†

ç»“è®ºï¼š

1. æ¯æ¬¡å¯¹dataloaderè¿›è¡Œé‡æ–°è°ƒç”¨ï¼ˆé‡æ–°æ”¾åˆ°enumerateï¼‰ï¼Œæˆ–è€…é‡æ–°å®šä¹‰iterï¼Œéƒ½ä¼šé‡æ–°è¿›è¡Œshuffleã€‚

num_worker

[å‚è€ƒèµ„æ–™1](https://www.cnblogs.com/hesse-summer/p/11343870.html)  å‚è€ƒèµ„æ–™2ï¼špytorchä¸­æ–‡æ–‡æ¡£ğŸ‘‡

**num_workers** (*int*, optional) â€“ ç”¨å¤šå°‘ä¸ªå­è¿›ç¨‹åŠ è½½æ•°æ®ã€‚0è¡¨ç¤ºæ•°æ®å°†åœ¨ä¸»è¿›ç¨‹ä¸­åŠ è½½(é»˜è®¤: 0)
ç”¨num_workerä¸ªå­è¿›ç¨‹åŠ è½½æ•°æ®ï¼Œæ‰€ä»¥èƒ½å¤Ÿå°†æ•°æ®åœ¨ä¸»è¿›ç¨‹å±•ç¤ºè¿˜æ²¡æœ‰è°ƒç”¨åˆ°è¯¥æ•°æ®ä¹‹å‰å°±å°†åç»­çš„æ•°æ®å­˜å…¥RAMï¼Œæ‰€ä»¥åœ¨æ•°æ®è¯»å–ä¸Šä¼šæ¯”è¾ƒå¿«ï¼Œä½†æ˜¯å ç”¨çš„RAMå’ŒCPUèµ„æºä¼šæ¯”è¾ƒå¤§ã€‚

samples:

[torch.utils.data - PyTorch 1.9.0 documentation](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader)

[ä¸€æ–‡å¼„æ‡‚Pytorchçš„DataLoader, DataSet, Samplerä¹‹é—´çš„å…³ç³»](https://www.cnblogs.com/marsggbo/p/11308889.html)

å®˜æ–¹çš„è§£é‡Šæ˜¯ï¼š

samplerÂ (SamplerÂ orÂ Iterable,Â optional)Â â€“Â definesÂ theÂ strategyÂ toÂ drawÂ samplesÂ fromÂ theÂ dataset.Â CanÂ beÂ anyÂ IterableÂ withÂ __len__Â implemented.Â IfÂ specified,Â shuffleÂ mustÂ notÂ beÂ specified.

å®šä¹‰ä»æ•°æ®é›†ï¼ˆè¿˜æ˜¯æœ€å¼€å§‹çš„å“ªä¸ªæ•°æ®é›†ï¼Œä¸èƒ½æ˜¯é¢å¤–çš„æ•°æ®é›†ï¼‰ä¸­æå–æ ·æœ¬çš„ç­–ç•¥ï¼šæ˜¯å¦èƒ½é€šè¿‡è¯¥Methodå»å®ç°Hard-Taskæˆ–è€…åƒMeta-Taskä¸€æ ·çš„é‡‡æ ·è¿‡ç¨‹å‘¢ï¼Ÿä»Meta-Transfer-Learningä¸­çœ‹æ¥æ˜¯å¯ä»¥çš„ï¼Œå¯ä»¥å­¦ä¹ ä¸€ä¸‹å®ƒçš„å†™æ³•ã€‚

#### collate_fn()

collate_fnçš„ä½œç”¨å°±æ˜¯å°†ä¸€ä¸ªbatchçš„æ•°æ®è¿›è¡Œåˆå¹¶æ“ä½œã€‚é»˜è®¤çš„collate_fnæ˜¯å°†imgå’Œlabelåˆ†åˆ«åˆå¹¶æˆimgså’Œlabelsï¼Œæ‰€ä»¥å¦‚æœä½ çš„__getitem__æ–¹æ³•åªæ˜¯è¿”å›Â img,Â label,é‚£ä¹ˆä½ å¯ä»¥ä½¿ç”¨é»˜è®¤çš„collate_fnæ–¹æ³•,
ä½†æ˜¯å¦‚æœä½ æ¯æ¬¡è¯»å–çš„æ•°æ®æœ‰img,Â box,Â labelç­‰ç­‰ï¼Œé‚£ä¹ˆä½ å°±éœ€è¦è‡ªå®šä¹‰collate_fnæ¥å°†å¯¹åº”çš„æ•°æ®åˆå¹¶æˆä¸€ä¸ªbatchæ•°æ®ï¼Œè¿™æ ·æ–¹ä¾¿åç»­çš„è®­ç»ƒæ­¥éª¤ã€‚

- ç¼–å†™collate_fnå¯ä»¥å‚è€ƒqidongçš„æ–‡ç« ä¸»è¦æ˜¯æ¥å—æ•°æ®å’Œæ ‡ç­¾åˆ—è¡¨ï¼Œå°†å…¶æ•´åˆæˆä¸€ä¸ªçŸ©é˜µçš„å½¢å¼;
- å¦‚æœå¯¹ä¼ å‚æœ‰éœ€æ±‚,å¯ä»¥å‚è€ƒ`lambda`çš„å½¢å¼æˆ–è€…æ˜¯ç±»å®šä¹‰çš„å½¢å¼å»ä¼ å…¥

```python
dataload = DataLoader(dataset, lambda x: collate_fn(x, **params))

class collater():
    def __init__(**params):
        self.params = ...
    
    def __call(self,datas):
        # make it a batch in this function, then we will instance this class
        ...
    def _helpful_fn(self):
        ...
```

using collate_fn, we can augment the dataset more flexible.

## ç¼–å†™æ¨¡å‹

### æ¨¡å‹åŸºæœ¬å•å…ƒ

nn.conv2Dï¼š

- kernel_size[1]åº”è¯¥æŒ‡çš„æ˜¯å·ç§¯æ ¸çš„å®½ï¼ˆä¸ä¸€å®šéƒ½æ˜¯æ­£æ–¹å½¢çš„ï¼‰

### æ¨¡å‹å‚æ•°å…±äº«ï¼š

[pytorchï¼šå¯¹æ¯”cloneã€detachä»¥åŠcopy_ç­‰å¼ é‡å¤åˆ¶æ“ä½œ](https://www.cnblogs.com/wwzone/articles/12917333.html)

```python
# å‡è®¾æœ‰modelaå’Œmodelbï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¿›è¡Œä¸‹é™çš„æ—¶å€™æ‰§è¡Œå‚æ•°ç»Ÿä¸€ï¼Œ
for a_para,b_para in zip(modela.parameters(),modelb.parameters()):
        b_para.data.copy_(a_para.data)
```

### ç½‘ç»œå®šä¹‰çš„æ–¹å¼å¯¹æ¯”åˆ†æ

@Aiken 2021 ä¸»è¦å¯¹æ¯”çš„æ˜¯ModuleListå’ŒSequtial

**ç»“è®ºï¼š**é€šå¸¸ä½¿ç”¨çš„è¯ï¼Œè¿™é‡Œæˆ‘ä¸ªäººæ¨èä½¿ç”¨çš„æ˜¯`sequtial`ç»“åˆ`collection`ä¸­çš„`orderdict`æ¥æ„å»ºçš„æ–¹æ³•ï¼Œè¿™ä¸ªæ–¹æ³•é›†æˆäº†å†…éƒ¨çš„`forward`ï¼ŒåŒæ—¶é€šè¿‡``orderdict`ä¹Ÿèƒ½ç»™printå¸¦æ¥æ›´å¥½çš„å¯è§†åŒ–æ•ˆæœã€‚

ä½†æ˜¯è¿˜æ˜¯æœ‰ä¸€äº›ç‰¹æ®Šçš„ä½¿ç”¨åœºæ™¯æˆ‘ä»¬ä¼šç”¨åˆ°`ModuleList`

[è¯¦è§£PyTorchä¸­çš„ModuleListå’ŒSequential](https://zhuanlan.zhihu.com/p/75206669)

ä¸»è¦åŒºåˆ«ï¼š

1. nn.Sequentialå†…éƒ¨å®ç°äº†forwardå‡½æ•°ï¼Œå› æ­¤å¯ä»¥ä¸ç”¨å†™forwardå‡½æ•°ã€‚è€Œnn.ModuleListåˆ™æ²¡æœ‰å®ç°å†…éƒ¨forwardå‡½æ•°ã€‚
2. nn.Sequentialå¯ä»¥ä½¿ç”¨OrderedDictå¯¹æ¯å±‚è¿›è¡Œå‘½åï¼Œä¸Šé¢å·²ç»é˜è¿°è¿‡äº†ï¼›
3. nn.Sequentialé‡Œé¢çš„æ¨¡å—æŒ‰ç…§é¡ºåºè¿›è¡Œæ’åˆ—çš„ï¼Œæ‰€ä»¥å¿…é¡»ç¡®ä¿å‰ä¸€ä¸ªæ¨¡å—çš„è¾“å‡ºå¤§å°å’Œä¸‹ä¸€ä¸ªæ¨¡å—çš„è¾“å…¥å¤§å°æ˜¯ä¸€è‡´çš„ã€‚è€Œnn.ModuleList å¹¶æ²¡æœ‰å®šä¹‰ä¸€ä¸ªç½‘ç»œï¼Œå®ƒåªæ˜¯å°†ä¸åŒçš„æ¨¡å—å‚¨å­˜åœ¨ä¸€èµ·ï¼Œè¿™äº›æ¨¡å—ä¹‹é—´å¹¶æ²¡æœ‰ä»€ä¹ˆå…ˆåé¡ºåºå¯è¨€ã€‚**ç½‘ç»œçš„æ‰§è¡Œé¡ºåºæŒ‰ç…§æˆ‘ä»¬åœ¨forwardä¸­æ€ä¹ˆç¼–å†™æ¥å†³å®šçš„**
4. æœ‰çš„æ—¶å€™ç½‘ç»œä¸­æœ‰å¾ˆå¤šç›¸ä¼¼æˆ–è€…é‡å¤çš„å±‚ï¼Œæˆ‘ä»¬ä¸€èˆ¬ä¼šè€ƒè™‘ç”¨ for å¾ªç¯æ¥åˆ›å»ºå®ƒä»¬ï¼Œè€Œä¸æ˜¯ä¸€è¡Œä¸€è¡Œåœ°å†™ï¼Œè¿™ç§æ—¶å€™å°±ä½¿ç”¨ModuleListï¼š

    ```python
    class net4(nn.Module):
        def __init__(self):
            super(net4, self).__init__()
            layers = [nn.Linear(10, 10) for i in range(5)]
            self.linears = nn.ModuleList(layers)
    
        def forward(self, x):
            for layer in self.linears:
                x = layer(x)
            return x
    
    net = net4()
    print(net)
    # net4(
    #   (linears): ModuleList(
    #     (0): Linear(in_features=10, out_features=10, bias=True)
    #     (1): Linear(in_features=10, out_features=10, bias=True)
    #     (2): Linear(in_features=10, out_features=10, bias=True)
    #   )
    # )
    
    ```

åŸºæœ¬ä½¿ç”¨ï¼š

1. nn.sequential

    å¯ä»¥é€šè¿‡listå’Œ*ä»¥åŠadd moudleæ¥è¿›è¡Œè¿­ä»£çš„å®šä¹‰ï¼ŒåŒæ—¶è¿™ç§å®šä¹‰æ–¹å¼ï¼Œä¼šæ–¹ä¾¿æˆ‘ä»¬çš„é‡å¤æ³¨å†Œ

    ```python
    from collections import OrderedDict

    class net_seq(nn.Module):
        def __init__(self):
            super(net_seq, self).__init__()
            self.seq = nn.Sequential(OrderedDict([
                            ('conv1', nn.Conv2d(1,20,5)),
                             ('relu1', nn.ReLU()),
                              ('conv2', nn.Conv2d(20,64,5)),
                           ('relu2', nn.ReLU())
                           ]))
        def forward(self, x):
            return self.seq(x)
    net_seq = net_seq()
    print(net_seq)
    #net_seq(
    #  (seq): Sequential(
    #    (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    #    (relu1): ReLU()
    #    (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))
    #    (relu2): ReLU()
    #  )
    #)

    ```

2. nn.ModuleList:ä¸pythonè‡ªå¸¦çš„Listä¸åŒçš„åœ°æ–¹åœ¨äºä»–ä¼šè‡ªåŠ¨å°†ç½‘ç»œæ³¨å†Œåˆ°Parameterä¸­ï¼Œæˆä¸ºç½‘ç»œï¼Œä½†æ˜¯éœ€è¦è‡ªå·±å»ç¼–å†™forwardè¿‡ç¨‹

    ```python
    class net_modlist(nn.Module):
        def __init__(self):
            super(net_modlist, self).__init__()
            self.modlist = nn.ModuleList([
                           nn.Conv2d(1, 20, 5),
                           nn.ReLU(),
                            nn.Conv2d(20, 64, 5),
                            nn.ReLU()
                            ])
    
        def forward(self, x):
            for m in self.modlist:
                x = m(x)
            return x
    
    net_modlist = net_modlist()
    print(net_modlist)
    #net_modlist(
    #  (modlist): ModuleList(
    #    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    #    (1): ReLU()
    #    (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))
    #    (3): ReLU()
    #  )
    #)
    
    for param in net_modlist.parameters():
        print(type(param.data), param.size())
    #<class 'torch.Tensor'> torch.Size([20, 1, 5, 5])
    #<class 'torch.Tensor'> torch.Size([20])
    #<class 'torch.Tensor'> torch.Size([64, 20, 5, 5])
    #<class 'torch.Tensor'> torch.Size([64])
    
    ```

### Detach & detach_

è¿™ä¸ªæ¨¡å—åœ¨åç»­è¿›è¡Œpretrainæˆ–è€…transferçš„æ—¶å€™åº”è¯¥ä¼šç»å¸¸è¢«ç”¨åˆ°ï¼Œæ‰€ä»¥è¿™ç§æ–¹æ³•è¿˜æ˜¯éœ€è¦ç†Ÿç»ƒæŒæ¡çš„

[è¯¦ç»†çš„åˆ†æä»‹ç»](https://www.cnblogs.com/wanghui-garcia/p/10677071.html)

`detach`æ˜¯äº§ç”Ÿä¸€ç»„ä¸éœ€è¦ä¸‹é™çš„â€œ`Copy`â€ï¼šå¦‚æœè¦ä¿®æ”¹åŸå€¼çš„è¯å°±è¦è¿›è¡Œèµ‹å€¼æ“ä½œã€‚

`detach_`åˆ™æ˜¯ä¿®æ”¹æœ¬èº«å‚æ•°çš„å±æ€§ï¼ˆ`require_grad`etc.ï¼‰æ‰§è¡Œå‡½æ•°å°±èƒ½å°†å‚æ•°ä¿®æ”¹ä¸ºä¸éœ€è¦ä¸‹é™çš„æƒ…å†µï¼Œä¸éœ€è¦æ‰§è¡Œèµ‹å€¼å¤„ç†ã€‚

### æ¨¡å‹è°ƒç”¨çš„Tips

**ä½¿ç”¨listè¿›è¡Œå¤šæ¨¡å‹çš„æ··åˆè°ƒç”¨**

ç”±äºpythoné»˜è®¤çš„æ˜¯å¼•ç”¨èµ‹å€¼ï¼Œä¹Ÿå°±æ˜¯æµ…æ‹·è´çš„æ–¹å¼ï¼Ÿ
é€šè¿‡listæ¥è¿›è¡Œæ¨¡å‹çš„æ‰¹é‡æ„å»ºï¼Œé€šè¿‡listæ¥å°†æ¨¡å‹æ•´åˆèµ·æ¥ï¼Œæ˜¯**ä¸ä¼š**ä½¿ç”¨**é¢å¤–çš„å­˜å‚¨ç©ºé—´**çš„ï¼Œå®ƒä»¬æŒ‡å‘åŒä¸€ä¸ªåœ°å€ã€‚åŸºäºè¿™æ ·çš„å‡è®¾ï¼Œæˆ‘ä»¬å¯ä»¥åŸºäºlistæ¥ç®€åŒ–ä»£ç ï¼Œé€šè¿‡LOOPæ¥æ‰§è¡Œï¼Œç›¸å…³çš„è°ƒç”¨æ“ä½œï¼Œæ¯”å¦‚ç”Ÿæˆå™¨æˆ–è€…é¢„æµ‹ä¹‹ç±»çš„ï¼Œæ¥**ç®€åŒ–**ä»£ç ç»“æ„ã€‚

```python
model1 = AET_model(3,4,5,**kwargs)
model2 = AET_model(3,4,5,**kwargs)
model_list = [model1,model2]
if id(model1)==id(model2):
    print('the address of those model is same, so donot need extra space')
# å…·ä½“å¯ä»¥ç®€åŒ–ä»€ä¹ˆç±»å‹çš„æ“ä½œï¼š
optimizer_list = []
for _, models_t in enumerate(model_list):
    optimizer_list.append(optim.SGD(
                            models_t.parameters(),
                            lr,momï¼Œwd))
optimizer1 = _[0]
optimizer2 = _[1]
# like this

```

### Warm-up factor

å¯¹äºè¿™ä¸€éƒ¨åˆ†çš„æ¦‚å¿µæˆ‘è¿˜æ˜¯æœ‰äº›ä¸äº†è§£ï¼Œæ˜¯å¦å’Œå†·å¯åŠ¨å’Œçƒ­å¯åŠ¨çš„æ¦‚å¿µæ˜¯ç›¸å…³çš„ï¼Œå¦‚æœä¸æ˜¯çš„è¯ï¼Œé¡ºä¾¿å°±å­¦ä¹ ä¸€ä¸‹å†·å¯åŠ¨å’Œçƒ­å¯åŠ¨çš„æ¦‚å¿µã€‚

å…·ä½“è§£æï¼š

1. [neural network - What does "learning rate warm-up" mean? - Stack Overflow](https://stackoverflow.com/questions/55933867/what-does-learning-rate-warm-up-mean)
2. [å…³äºwarm_upå­¦ä¹ ç‡_äº‘ä¸­å¯»é›¾çš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/qq_36387683/article/details/97265084)

[pytorchå­¦ä¹ ç‡è°ƒæ•´æ–¹æ³•ï¼ˆwarm upï¼‰ ï¼Œlabel smoothã€apexæ··åˆç²¾åº¦è®­ç»ƒã€æ¢¯åº¦ç´¯åŠ _xys430381_1çš„ä¸“æ -CSDNåšå®¢](https://blog.csdn.net/xys430381_1/article/details/107468446)

[ç¥ç»ç½‘ç»œä¸­ warmup ç­–ç•¥ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼›æœ‰ä»€ä¹ˆç†è®ºè§£é‡Šä¹ˆï¼Ÿ](https://www.zhihu.com/question/338066667)

### Weight decayï¼ˆL2ï¼‰

å®é™…ä¸Šå°±æ˜¯å¯¹æƒé‡è¿›è¡ŒL2æ­£åˆ™åŒ–ï¼Œè®©æƒé‡è¡°å‡åˆ°æ›´å°çš„å€¼ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡å°‘æ¨¡å‹çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæ‰€ä»¥æƒé‡è¡°å‡å®é™…ä¸Šä¹Ÿå«L2æ­£åˆ™åŒ–ã€‚

å…·ä½“çš„æ•°å­¦æ¨å¯¼åç»­å°†é›†æˆåˆ°**GoodNoteç¬”è®°**ä¸Šï¼Œå°†æ­£åˆ™åŒ–å•ç‹¬ä½œä¸ºä¸€ä¸ªæ¨¡å—å»æ•´ç†ã€‚

**æƒé‡è¡°å‡ï¼ˆL2æ­£åˆ™åŒ–ï¼‰çš„ä½œç”¨**

**ä½œç”¨ï¼š** æƒé‡è¡°å‡ï¼ˆL2æ­£åˆ™åŒ–ï¼‰å¯ä»¥é¿å…æ¨¡å‹è¿‡æ‹Ÿåˆé—®é¢˜ã€‚

**æ€è€ƒï¼š** L2æ­£åˆ™åŒ–é¡¹æœ‰è®©wå˜å°çš„æ•ˆæœï¼Œä½†æ˜¯ä¸ºä»€ä¹ˆwå˜å°å¯ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆå‘¢ï¼Ÿ

**åŸç†ï¼š** ï¼ˆ1ï¼‰ä»æ¨¡å‹çš„å¤æ‚åº¦ä¸Šè§£é‡Šï¼šæ›´å°çš„æƒå€¼wï¼Œä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œè¡¨ç¤ºç½‘ç»œçš„å¤æ‚åº¦æ›´ä½ï¼Œå¯¹æ•°æ®çš„æ‹Ÿåˆæ›´å¥½ï¼ˆè¿™ä¸ªæ³•åˆ™ä¹Ÿå«åšå¥¥å¡å§†å‰ƒåˆ€ï¼‰ï¼Œè€Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œä¹ŸéªŒè¯äº†è¿™ä¸€ç‚¹ï¼ŒL2æ­£åˆ™åŒ–çš„æ•ˆæœå¾€å¾€å¥½äºæœªç»æ­£åˆ™åŒ–çš„æ•ˆæœã€‚ï¼ˆ2ï¼‰ä»æ•°å­¦æ–¹é¢çš„è§£é‡Šï¼šè¿‡æ‹Ÿåˆçš„æ—¶å€™ï¼Œæ‹Ÿåˆå‡½æ•°çš„ç³»æ•°å¾€å¾€éå¸¸å¤§ï¼Œä¸ºä»€ä¹ˆï¼Ÿå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¿‡æ‹Ÿåˆï¼Œå°±æ˜¯æ‹Ÿåˆå‡½æ•°éœ€è¦é¡¾å¿Œæ¯ä¸€ä¸ªç‚¹ï¼Œæœ€ç»ˆå½¢æˆçš„æ‹Ÿåˆå‡½æ•°æ³¢åŠ¨å¾ˆå¤§ã€‚åœ¨æŸäº›å¾ˆå°çš„åŒºé—´é‡Œï¼Œå‡½æ•°å€¼çš„å˜åŒ–å¾ˆå‰§çƒˆã€‚è¿™å°±æ„å‘³ç€å‡½æ•°åœ¨æŸäº›å°åŒºé—´é‡Œçš„å¯¼æ•°å€¼ï¼ˆç»å¯¹å€¼ï¼‰éå¸¸å¤§ï¼Œç”±äºè‡ªå˜é‡å€¼å¯å¤§å¯å°ï¼Œæ‰€ä»¥åªæœ‰ç³»æ•°è¶³å¤Ÿå¤§ï¼Œæ‰èƒ½ä¿è¯å¯¼æ•°å€¼å¾ˆå¤§ã€‚è€Œæ­£åˆ™åŒ–æ˜¯é€šè¿‡çº¦æŸå‚æ•°çš„èŒƒæ•°ä½¿å…¶ä¸è¦å¤ªå¤§ï¼Œæ‰€ä»¥å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡å°‘è¿‡æ‹Ÿåˆæƒ…å†µã€‚

![https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175236273.png](https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175236273.png)

image-20201205175236273

å†…å®¹æ¥è‡ªï¼š [æ­£åˆ™åŒ–æ–¹æ³•ï¼šL1å’ŒL2 regularizationã€æ•°æ®é›†æ‰©å¢ã€dropout](https://blog.csdn.net/u012162613/article/details/44261657)

### Learning Rate Decay

å½“æˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªåˆé€‚çš„lrï¼Œä½†æ˜¯æŸå¤±è®­ç»ƒåˆ°ä¸€å®šç¨‹åº¦ä»¥åå°±ä¸å†ä¸‹é™äº†ï¼Œå°±åœ¨ä¸€ä¸ªåŒºé—´ä¸­æ¥å›åŠ¨è¡ï¼Œå¯èƒ½æ˜¯å‡ºç°äº†ä¸€ä¸‹çš„é—®é¢˜ï¼š

![https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175605729.png](https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175605729.png)

image-20201205175605729

å¯¹è¿™ç§é—®é¢˜çš„è§£å†³å°±æ˜¯é€šè¿‡å­¦ä¹ ç‡è¡°å‡æ¥å®ç°çš„ï¼šå°†å­¦ä¹ ç‡éšç€è®­ç»ƒçš„è¿›è¡Œæ¥è¿›è¡Œè¡°å‡ï¼Œè¿™ä¸ªæ–¹æ³•å°±æ¯”è¾ƒç›´è§‚äº†ã€‚å…·ä½“çš„æ–¹æ³•æè¿°å¯ä»¥åœ¨ `../project_note/è®­ç»ƒå‚æ•°è°ƒæ•´ç­–ç•¥.md`ä¸­æ‰¾åˆ°ã€‚

ä¹Ÿå¯ä»¥å‚è€ƒå¦‚ä¸‹è¿æ¥ï¼š[è¯¦ç»†ç†è§£pytorchçš„å…­ç§å­¦ä¹ ç‡pytorch](https://blog.csdn.net/weixin_42662358/article/details/93732852)

## æŸå¤±å‡½æ•°

nnä¸­è‡ªå¸¦çš„Loss Functionæ¯”å¦‚è¯´MSEä¹‹ç±»çš„ï¼Œè®¡ç®—å‡ºæ¥çš„å€¼æœ¬èº«å°±å·²ç»å¯¹batchå–äº†å¹³å‡å€¼ï¼ŒåŒæ—¶æˆ‘ä»¬è¿›è¡Œäº¤å‰ç†µçš„è®¡ç®—çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸éœ€è¦å®ç°å¯¹ä»–è¿›è¡Œsoftmaxï¼Œå› ä¸ºå†CEä¸­å·²ç»é›†æˆäº†softmaxçš„æ“ä½œã€‚

### CrossEntropyäº¤å‰ç†µ

è¿™é‡Œä¼šä»‹ç»ä¸€ä¸‹Pytorchä¸­çš„CEæŸå¤±çš„å…·ä½“å®ç°çš„æ–¹æ³•ï¼Œè¿™é‡Œç»™å‡ºä¸‰ç§æ–¹å¼çš„å¯¹æ¯”ã€‚

```python
import torch
# initial data and calculate method
input_x = torch.randn((4,5))
label = torch.tensor((1,2,3,4))
cri = torch.nn.CrossEntropyLoss()
nll_f = torch.nn.NLLLoss()

# output softmax and logsoftmax and pred
softamx_x = torch.softmax(input_x,dim=1)
logsoftmax_x = torch.log(softamx_x)
print("softamx_x \n", softamx_x)
print("pre_res \n", softamx_x.argmax(axis=1))
print("log_softamx_x \n", logsoftmax_x)

# calculate official ce and NLL
print("torch ce \n",cri(input_x,label))
print("nll_cal \n", nll_f(logsoftmax_x,label))

# calculate the manual ce loss we cal
res = [-logsoftmax_x[i][label[i]] for i in range(len(label))]
print("manual cal \n",sum(res)/len(label))

```

å¯ä»¥å‘ç°ä¸‰ç§æ–¹å¼è®¡ç®—å‡ºæ¥çš„æŸå¤±æ˜¯ä¸€æ ·çš„ï¼Œè¿™å°±è¯´æ˜äº†æˆ‘ä»¬åœ¨è®¡ç®—çš„æ—¶å€™è¦è®°ä½ï¼Œceä¸­æ˜¯è‡ªå·±é›†æˆäº†softmaxçš„æ“ä½œï¼ŒåŒæ—¶åœ¨Nllä¸­æ˜¯å­˜åœ¨äº†å–negativeçš„æ“ä½œçš„ã€‚æŒ‰ç…§è¿™ä¸ªæ“ä½œæ‰‹å†Œå»å®ç°è‡ªå·±ç›¸åº”çš„æŸå¤±å‡½æ•°è®¾è®¡

## ä¼˜åŒ–å™¨è®¾è®¡

è¿™ä¸€éƒ¨åˆ†ä¸»è¦æ·»åŠ ä¸€äº›å¸¸è§çš„ä¼˜åŒ–å™¨å‚æ•°çš„è®¾ç½®åŒ…æ‹¬SGDå’ŒAdamçš„å¯¹åº”è®¾ç½®ï¼Œä¸»è¦ä»‹ç»ä¸€ä¸‹è®¾ç½®Adam
å®é™…ä¸ŠAdamçš„è®¾ç½®å¯¹äºå­¦ä¹ ç‡æ¥è¯´æ²¡æœ‰é‚£ä¹ˆæ•æ„Ÿï¼Œä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯è¦äº†è§£å‚æ•°çš„æ„æ€æ‰çŸ¥é“æ€ä¹ˆå»è®¾ç½®è¯¥ä¼˜åŒ–å™¨

## æ¨¡å‹å‚æ•°åˆå§‹åŒ–å’Œæ¶æ„æŸ¥çœ‹æ–¹æ³•

å®é™…ä¸Šå¯¹å‚æ•°åˆå§‹åŒ–ä¹Ÿå°±æ˜¯éœ€è¦å¯¹æ•´ä½“çš„æ¶æ„è¿›è¡Œéå†ï¼Œæ‰€ä»¥è¿™ä¸¤ä¸ªä¼šå½’ä¸ºä¸€ä¸ªå­è¯¾é¢˜

å‚æ•°çš„åˆå§‹åŒ–æ–¹æ³•åªè¦ä½¿ç”¨å¦‚ä¸‹çš„æ–¹å¼ï¼Œæ— è®ºæˆ‘ä»¬é‡‡å–é‚£ç§å®šä¹‰çš„æ–¹å¼ï¼Œï¼Œéƒ½èƒ½éå†åˆ°å…¶ä¸­æ‰€åŒ…å«çš„æ‰€æœ‰ç½‘ç»œå±‚

```python
# å¦‚æœç›´æ¥åœ¨ç½‘ç»œå®šä¹‰çš„æ—¶å€™ç›´æ¥è¿›è¡Œåˆå§‹åŒ–
for m in self.modules():
    if isinstance(m,nn.Conv2d):
        nn.init.kaiming_normal_(m.weight,mode='fan_out')
    if isinstance(m,nn.BatchNorm2d):
        nn.init.constant_(m.weight,1)
        nn.init.constant_(m.bias,1)
# å¦‚æœæ˜¯åœ¨æ¨¡å‹å®šä¹‰çš„å¤–éƒ¨çš„è¯
for layer in model.modules():
  if isinstance(layer, torch.nn.Conv2d):
      torch.nn.init.kaiming_normal_(layer.weight,mode='fan_out', nonlinearity='relu')
  if layer.bias isnotNone:
      torch.nn.init.constant_(layer.bias, val=0.0)
  elif isinstance(layer, torch.nn.BatchNorm2d):
      torch.nn.init.constant_(layer.weight, val=1.0) torch.nn.init.constant_(layer.bias, val=0.0)
  elif isinstance(layer, torch.nn.Linear):
      torch.nn.init.xavier_normal_(layer.weight)
  if layer.bias isnotNone:
      torch.nn.init.constant_(layer.bias, val=0.0)
      layer.weight = torch.nn.Parameter(tensor)
# ä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»–çš„æ–¹æ³•æ¯”å¦‚parametersï¼Œchildren

```

### childrenã€modulesã€parametersï¼š

`model.modules`ä¼šéå†modelä¸­æ‰€æœ‰çš„å­å±‚ï¼Œè€Œ`children`åªä¼šéå†å½“å‰å±‚ï¼Œä¹Ÿå°±æ˜¯æœ€å¤–å±‚çš„æƒ…å†µï¼Œæ‰€ä»¥å¦‚æœè¦è¿›è¡Œå‚æ•°çš„åˆå§‹åŒ–çš„è¯ï¼Œæœ€å¥½æ˜¯ç”¨ç±»å†…æˆ–è€…ç±»å¤–çš„ä¸¤ç§æ–¹æ³•æ¥å®ç°åˆå§‹åŒ–

`parameter`è¿”å›çš„æ˜¯æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ï¼Œæ‰€ä»¥åˆå§‹åŒ–æœ€å¥½ä½¿ç”¨çš„æ˜¯``modules`ï¼Œè€Œparameterä¸€èˆ¬ç”¨æ¥åˆå§‹åŒ–å‚æ•°

**ç”¨numelä¸parametersè®¡ç®—å‚æ•°çš„ä¸ªæ•°**

```python
#å¯ä»¥ç®€æ´çš„å†™æˆä¸‹é¢çš„å½¢å¼
#numel()å‡½æ•°æœ¬èº«çš„ä½œç”¨æ˜¯è¿”å›æ•°ç»„ä¸­å…ƒç´ çš„ä¸ªæ•°
def count_parameters(model):
    return sum(P.numel() for P in model.parameters() if P.requires_grad)

#å¸®åŠ©ç†è§£çš„ç»“æ„å½¢å¼å¯ä»¥è¡¨è¾¾å¦‚ä¸‹ï¼š
def count_parameters(model):
    for p in model.parameters():
        if p.requires_grad:
            ans += p.numel()

```

### åˆå§‹åŒ–åŸåˆ™ï¼šï¼ˆç»§ç»­è°ƒç ”ï¼‰

[pytorchä¸­çš„å‚æ•°åˆå§‹åŒ–æ–¹æ³•æ€»ç»“_ys1305çš„åšå®¢-CSDNåšå®¢_pytorch å‚æ•°åˆå§‹åŒ–](https://blog.csdn.net/ys1305/article/details/94332007)

**Batch-Normalization**ï¼š[Batch Normalizationè¯¦è§£ - shine-lee - åšå®¢å›­ (cnblogs.com)](https://www.cnblogs.com/shine-lee/p/11989612.html)

- convï¼š`kaming_normal_`
- fcï¼š`constan_,xvaier`
- bnï¼š`normal_\constant|`

### å…¸å‹çš„å‚æ•°åˆå§‹åŒ–æ–¹æ³•

EnAETä¸­å¯ä»¥çœ‹åˆ°å‚è€ƒçš„æºç å¦‚ä¸‹ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒBNä¸­åªæœ‰ä¸¤ä¸ªå‚æ•°ï¼Œæ‰€ä»¥ä¸éœ€è¦è¿›è¡Œå‚æ•°çš„åˆå§‹åŒ–ï¼Œæˆ–è€…ç›´æ¥ç½®0ã€1å³å¯.

```python
for m in self.modules():
    if isinstance(m,nn.Conv2d):
        # è®¡ç®—å‚æ•°
        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
        m.weight.data.normal_(0,math.sqrt(2. / n))
    elif isinstance(m,nn.BatchNorm2d):
        m.weight.data.fill_(1)
        m.bias.data.zero_()
    elif isinstance(m, nn.Linear):
        nn.init.xavier_normal_(m.weight.data)    # what's this method
        m.bias.data.zero_()

```

## æ•°æ®ç±»å‹å’Œç»´åº¦

åœ¨ç®—æ³•ç¼–å†™çš„è¿‡ç¨‹ä¸­ï¼Œæ•°æ®çš„ç±»å‹å’Œç»´åº¦çš„å¯¹é½å’Œchannelæ˜¯å¾ˆé‡è¦çš„ï¼Œåœ¨è¿™é‡Œä¹Ÿå¾ˆå®¹æ˜“å‡ºç°å¾ˆå¤šçš„bugï¼Œåœ¨è¿™é‡Œåšä¸€ä¸ªä¿¡æ¯çš„æ±‡æ€»

### è¾“å…¥æ•°æ®çš„é€šé“

ç»“è®ºï¼špytorchç½‘ç»œè¾“å…¥å›¾ç‰‡çš„shapeè¦æ±‚é€šé“æ˜¯**channel_first**ï¼ˆé€šé“åœ¨å‰ï¼‰çš„ï¼Œæ‰€ä»¥å¦‚æœæˆ‘ä»¬çš„å›¾ç‰‡ä¸æ˜¯è¿™æ ·çš„è¯ï¼Œæˆ‘ä»¬å°±éœ€è¦æ‰§è¡Œç›¸åº”çš„å˜åŒ–ã€‚

TODOï¼šæ•´ç†å„ç§æ•°æ®è¯»å–æ–¹å¼è¯»å…¥çš„channel first æˆ–æ˜¯ last : skimage,PIL,numpy

æ•´ç†ç›¸åº”çš„å„ç§æ•°æ®ç±»å‹è¿›è¡Œtransposeï¼ˆnumpyï¼‰çš„æ–¹å¼

```python
# ä¹Ÿå¯ä»¥ä½¿ç”¨viewå‡½æ•°ï¼Œä½†æ˜¯ç›¸åº”çš„ï¼Œviewéœ€è¦è®¡ç®—å‡ºå„ä¸ªç»´åº¦ç›¸åº”çš„æ•°å€¼
# viewï¼ˆï¼‰ç›´æ¥ä½¿ç”¨çš„æ—¶å€™ä¸æ”¹å˜åŸå€¼çš„å¤§å°ï¼Œpermuteä¹Ÿä¸æ”¹å˜ï¼Œä½¿ç”¨çš„æ–¹æ³•ä¸åŒè€Œå·²
if img.shape[-1] == 3:
    img = img.permute(0,3,1,2)

```

### æ ‡ç­¾çš„å½¢å¼è½¬æ¢one-hot

è¿›è¡Œè®­ç»ƒä¹‹å‰è¦å°†æ•°æ®è½¬åŒ–ä¸ºonehotçš„å½¢å¼ï¼Œæ‰èƒ½è¾“å…¥è®­ç»ƒï¼Œè€Œä¸”ä¸€èˆ¬å› ä¸ºæ˜¯batch_sizeçš„å½¢å¼ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è½¬åŒ–ä¸ºçŸ©é˜µå½¢å¼çš„onehotï¼Œä¸èƒ½ç”¨å•ä¸ªlabelçš„è½¬åŒ–æ–¹æ³•ã€‚

```python
def make_onehot_single(num,index):
    '''æ ¹æ®ç±»åˆ«æ•°é‡å’Œindexç”Ÿæˆsingleï¼Œonehot'''
    # BTWï¼šscatteræ–¹æ³•ä¹Ÿèƒ½ç”Ÿæˆone-hot
    onehot = torch.zeros(num)
    onehot[index] = 1.0

    return onehot

# ä¸»è¦æ˜¯ä¸‹é¢è¿™ç§æ–¹æ³•éœ€è¦æŒæ¡ï¼Œ
def make_onehot_array(width,target):
    '''æ ¹æ®labelç”ŸæˆonehotçŸ©é˜µã€‚
    widthï¼šç±»åˆ«æ•° targetï¼šå…·ä½“çš„labeldata'''
    try:
        length = len(target.view(-1,1))
    except ValueError:
        print('the type of target is {} '.format(type(target)))
        print(target)
        raise Exception('break down')
    onehot = torch.zeros(length, width).scatter_(1,target.view(-1,1),1)

    return onehot

```

# Visualize å¯è§†åŒ–éƒ¨åˆ†

## Tensorboard in Pytorch

@Aiken H 2021 review  ä¹‹å‰è¿™ä¸€éƒ¨åˆ†çš„projectionå’Œmodeléƒ½æ²¡æœ‰æˆåŠŸæ˜¾ç¤ºï¼Œè¿™æ¬¡åœ¨æ–°æ¡†æ¶ä¸­å±•ç¤ºä¸€ä¸‹ã€‚

[Visualizing Models, Data, and Training with TensorBoard - PyTorch Tutorials 1.8.1+cu102 documentation](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)

[è¯¦è§£PyTorché¡¹ç›®ä½¿ç”¨TensorboardXè¿›è¡Œè®­ç»ƒå¯è§†åŒ–_æµ…åº¦å¯º-CSDNåšå®¢_tensorboardx](https://blog.csdn.net/bigbennyguo/article/details/87956434)

[ä½¿ç”¨ TensorBoard å¯è§†åŒ–æ¨¡å‹ï¼Œæ•°æ®å’Œè®­ç»ƒ (apachecn.org)](https://pytorch.apachecn.org/#/docs/1.7/17?id=ä½¿ç”¨-tensorboard-å¯è§†åŒ–æ¨¡å‹ï¼Œæ•°æ®å’Œè®­ç»ƒ)

åœ¨pytorchæ•™ç¨‹ä¸­çš„Projectionå¯ä»¥ç»“åˆåç»­è¾“å‡ºçš„Featureä½¿ç”¨æ¥åˆ†æç›¸åº”çš„èšç±»å’Œåˆ†ç±»å¯é æ€§

å¯ä»¥å°è¯•ä½¿ç”¨ï¼Œæ•™ç¨‹å†™çš„å¾ˆç®€å•æ˜“æ‡‚ã€‚

### Histogram ç›´æ–¹å›¾å‚æ•°ç»Ÿè®¡

ä¸€èˆ¬æ¥è¯´ç”¨æ¥ç»Ÿè®¡æ¨¡å‹ä¸­é—´çš„ä¸€äº›å‚æ•°çš„åˆ†å¸ƒæƒ…å†µï¼Œå…·ä½“çš„ä½¿ç”¨åœ¨è®­ç»ƒçš„epochä¹‹é—´ï¼Œå’Œvalæ˜¯ä¸€ä¸ªæ¯”è¾ƒç±»ä¼¼çš„æœºåˆ¶ï¼Œå…·ä½“çš„ä»£ç æ ·ä¾‹å¦‚ä¸‹ï¼š

```python
# visualize those parameter as historgram
# we can add other model here
if i % 10 == 0:
    for name,param in self.main_model.named_parameters():
        self.writer.add_histogram('main_model'+name,param.clone().cpu().data.numpy(),i)
    pass
```



### Embedding Projection

@Aiken H 2021 è¿™ä¸€éƒ¨åˆ†å¯èƒ½æ‰æ˜¯ç¥ç»ç½‘ç»œçš„ç‰¹å¾åˆ†å¸ƒçš„å¯è§†åŒ–å›¾ã€‚

ä¸‹é¢è¿™ä¸ªæ˜¯Googleçš„Embedding Projectionï¼Œéœ€è¦ä¸Šä¼ .tsvä¿å­˜çš„æ•°æ®ï¼Œä½†æ˜¯å®é™…ä¸Šå°±æ˜¯Tensorboardä¸Šä¹Ÿæœ‰é›†æˆçš„åŠŸèƒ½

[Embedding projector - visualization of high-dimensional data](http://projector.tensorflow.org/)

[Visualizing Data using the Embedding Projector in TensorBoard](https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin)



### PR_CURVE

è¿™é‡Œä¼šè´´ä¸Špr_curveä¸­éœ€è¦çš„å‚æ•°å’Œæˆ‘ä»¬è¿™è¾¹ç¼–å†™çš„ç¤ºä¾‹ä»£ç 



### Add_TEXT

æ¢è¡Œå¤±æ•ˆé—®é¢˜, è¿™æ˜¯å› ä¸ºåœ¨Tensorboardä¸­è¿™ä¸€éƒ¨åˆ†ä½¿ç”¨çš„æ˜¯Markdownçš„æ ¼å¼, æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘ä»¬åœ¨æ¢è¡Œç¬¦`\n`ä¹‹å‰, éœ€è¦ä¿ç•™ä¸¤ä¸ªç©ºæ ¼æ‰èƒ½å®ç°çœŸæ­£çš„æ¢è¡Œ



### ADD_Figure

æœ‰æ—¶å€™æˆ‘ä»¬ä¼šå‘ç°æˆ‘ä»¬ç¼–å†™çš„figureåœ¨stepä¸­æ²¡æœ‰å…¨éƒ¨ç°å®å‡ºæ¥, è¿™æ˜¯æˆ‘ä»¬å¯ä»¥é€šè¿‡å¯åŠ¨å‘½ä»¤æ¥å±•ç¤ºæ‰€æœ‰çš„å›¾ç‰‡

```python
--samples_per_plugin images=9999
# 999 > the num you want to displ
```



## å¯è§†åŒ–ç¥ç»ç½‘ç»œçƒ­åŠ›å›¾ï¼ˆCAMï¼‰

@Aiken2020 ä¸ºäº†ä¾¿äºæŸ¥çœ‹ç¥ç»ç½‘ç»œçš„**è¾“å‡º**ï¼Œå¯¹äºå›¾åƒçš„å“ªä¸€éƒ¨åˆ†**æ›´åŠ çš„ä¾§é‡**ï¼Œä¹Ÿå°±æ˜¯æŒ‡å¯¼ç½‘ç»œè¿›è¡Œåˆ†ç±»çš„ä¸»è¦æ˜¯å›¾åƒçš„å“ªäº›åŒºåŸŸï¼Œï¼ˆç›¸åº”çš„ä¹Ÿå¯ä»¥æŒ‰ç…§ç±»ä¼¼çš„æ–¹æ³•æŸ¥çœ‹Attention Networkçš„æ•ˆæœæŠŠï¼‰ï¼Œå°±æƒ³ç€**å¯è§†åŒ–ä¸€ä¸‹CAM**ã€‚çœ‹æŒ‡å¯¼åˆ†ç±»çš„é«˜å“åº”åŒºåŸŸæ˜¯å¦è½åœ¨æ ¸å¿ƒåŒºåŸŸã€‚

å‚è€ƒé“¾æ¥ï¼š

[CAM Pytorch](https://blog.csdn.net/sinat_37532065/article/details/103362517)

### ç®—æ³•åŸç†

å…¶è®¡ç®—æ–¹æ³•å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚å¯¹äºä¸€ä¸ªCNNæ¨¡å‹ï¼Œå¯¹å…¶æœ€åä¸€ä¸ªfeaturemapåšå…¨å±€å¹³å‡æ± åŒ–ï¼ˆGAPï¼‰è®¡ç®—å„é€šé“å‡å€¼ï¼Œç„¶åé€šè¿‡FCå±‚ç­‰æ˜ å°„åˆ°class scoreï¼Œæ‰¾å‡ºargmaxï¼Œ**è®¡ç®—æœ€å¤§çš„é‚£ä¸€ç±»çš„è¾“å‡ºç›¸å¯¹äºæœ€åä¸€ä¸ªfeaturemapçš„æ¢¯åº¦**ï¼ˆå®é™…ä¸Šå°±æ˜¯æœ€åä¸€ä¸ªmapä¸­å“ªäº›å¯¹äºåˆ†ç±»çš„å˜åŒ–å…¶æ›´å¤§çš„ä½œç”¨ï¼Œä¹Ÿå°±æ˜¯ç±»ä¼¼æƒé‡çš„æœºåˆ¶ï¼‰ï¼Œå†æŠŠè¿™ä¸ªæ¢¯åº¦å¯è§†åŒ–åˆ°åŸå›¾ä¸Šå³å¯ã€‚ç›´è§‚æ¥è¯´ï¼Œå°±æ˜¯çœ‹ä¸€ä¸‹**ç½‘ç»œæŠ½å–åˆ°çš„é«˜å±‚ç‰¹å¾çš„å“ªéƒ¨åˆ†å¯¹æœ€ç»ˆçš„classifierå½±å“æ›´å¤§**ã€‚

![ImgInGIthu](https://raw.githubusercontent.com/AikenH/md-image/master/img/20191203102807477.png)



- Quote: æ‰¾åˆ°äº†ä¸€ç¯‡åŸºäºKerasçš„CAMå®ç°ï¼Œæ„Ÿè°¢ï¼š

    https://blog.csdn.net/Einstellung/article/details/82858974 ä½†æ˜¯æˆ‘è¿˜æ˜¯ä¹ æƒ¯ç”¨Pytorchä¸€ç‚¹ï¼Œæ‰€ä»¥å‚è€ƒç€æ”¹äº†ä¸€ç‰ˆPytorchçš„å®ç°ã€‚å…¶ä¸­ï¼Œæœ‰ä¸€ä¸ªåœ°æ–¹å›°æ‰°äº†ä¸€ä¸‹ï¼Œå› ä¸ºPytorchçš„è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ï¼Œä¸€èˆ¬åªä¼šä¿å­˜å‡½æ•°å€¼å¯¹è¾“å…¥çš„å¯¼æ•°å€¼ï¼Œè€Œä¸­é—´å˜é‡çš„å¯¼æ•°å€¼éƒ½æ²¡æœ‰ä¿ç•™ï¼Œè€Œæ­¤å¤„æˆ‘ä»¬éœ€è¦è®¡ç®—è¾“å‡ºå±‚ç›¸å¯¹äºæœ€åä¸€ä¸ªfeature mapæ¢¯åº¦ï¼Œæ‰€ä»¥å‚è€ƒhttps://blog.csdn.net/qq_27061325/article/details/84728539è§£å†³äº†è¯¥é—®é¢˜ã€‚

### ä»£ç å®ç°ï¼š

```python
import os
from PIL import Image
import torch
import numpy as np
import cv2
import matplotlib.pyplot as plt

def draw_CAM(model, img_path, save_path, transform=None, visual_heatmap=False):
    '''
    ç»˜åˆ¶ Class Activation Map
    :param model: åŠ è½½å¥½æƒé‡çš„Pytorch model
    :param img_path: æµ‹è¯•å›¾ç‰‡è·¯å¾„
    :param save_path: CAMç»“æœä¿å­˜è·¯å¾„
    :param transform: è¾“å…¥å›¾åƒé¢„å¤„ç†æ–¹æ³•
    :param visual_heatmap: æ˜¯å¦å¯è§†åŒ–åŸå§‹heatmapï¼ˆè°ƒç”¨matplotlibï¼‰
    :return:
    '''
    # å›¾åƒåŠ è½½&é¢„å¤„ç†
    img = Image.open(img_path).convert('RGB')
    if transform:
        img = transform(img)
    img = img.unsqueeze(0)

    # è·å–æ¨¡å‹è¾“å‡ºçš„feature/score
    model.eval()
    features = model.features(img)
    output = model.classifier(features)

    # ä¸ºäº†èƒ½è¯»å–åˆ°ä¸­é—´æ¢¯åº¦å®šä¹‰çš„è¾…åŠ©å‡½æ•°
    def extract(g):
        global features_grad
        features_grad = g

    # é¢„æµ‹å¾—åˆ†æœ€é«˜çš„é‚£ä¸€ç±»å¯¹åº”çš„è¾“å‡ºscore
    pred = torch.argmax(output).item()
    pred_class = output[:, pred]

    features.register_hook(extract)
    pred_class.backward() # è®¡ç®—æ¢¯åº¦

    grads = features_grad   # è·å–æ¢¯åº¦

    pooled_grads = torch.nn.functional.adaptive_avg_pool2d(grads, (1, 1))

    # æ­¤å¤„batch sizeé»˜è®¤ä¸º1ï¼Œæ‰€ä»¥å»æ‰äº†ç¬¬0ç»´ï¼ˆbatch sizeç»´ï¼‰
    pooled_grads = pooled_grads[0]
    features = features[0]
    # 512æ˜¯æœ€åä¸€å±‚featureçš„é€šé“æ•°
    for i in range(512):
        features[i, ...] *= pooled_grads[i, ...]

    # ä»¥ä¸‹éƒ¨åˆ†åŒKerasç‰ˆå®ç°
    heatmap = features.detach().numpy()
    heatmap = np.mean(heatmap, axis=0)

    heatmap = np.maximum(heatmap, 0)
    heatmap /= np.max(heatmap)

    # å¯è§†åŒ–åŸå§‹çƒ­åŠ›å›¾
    if visual_heatmap:
        plt.matshow(heatmap)
        plt.show()

    img = cv2.imread(img_path)  # ç”¨cv2åŠ è½½åŸå§‹å›¾åƒ
    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))  # å°†çƒ­åŠ›å›¾çš„å¤§å°è°ƒæ•´ä¸ºä¸åŸå§‹å›¾åƒç›¸åŒ
    heatmap = np.uint8(255 * heatmap)  # å°†çƒ­åŠ›å›¾è½¬æ¢ä¸ºRGBæ ¼å¼
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)  # å°†çƒ­åŠ›å›¾åº”ç”¨äºåŸå§‹å›¾åƒ
    superimposed_img = heatmap * 0.4 + img  # è¿™é‡Œçš„0.4æ˜¯çƒ­åŠ›å›¾å¼ºåº¦å› å­
    cv2.imwrite(save_path, superimposed_img)  # å°†å›¾åƒä¿å­˜åˆ°ç¡¬ç›˜

```

## BUGs

å¦‚æœæƒ³è¦å±•ç¤ºå‡ºæ‰€æœ‰stepçš„å›¾ç‰‡, æˆ‘ä»¬å¯ä»¥åœ¨å‘½ä»¤è¡Œé‡Œæ‰§è¡Œtensoroardçš„æ—¶å€™æ‰§è¡Œä¸‹åˆ—å‘½ä»¤.

```bash
tensorboard --logdir log/cifar100_resnet18 --samples_per_plugin images=999999
```

 

# DEBUG

## 1.ImportError: cannot import name 'PILLOW_VERSION'

PILç‰ˆæœ¬è¿‡é«˜ï¼Œæ¢ä½å°±å¯ä»¥ï¼Œä»–ä¸é…æ˜¯ä¸€ä¸ªæ£˜æ‰‹çš„é—®é¢˜

`pip install Pillow==6.2.2 --user`

## 2.æ¨¡å‹å‚æ•°&è®¡ç®—é‡ç»Ÿè®¡ and Debugè¾“å‡º

1. ç”¨æ¥è®¡ç®—æ¨¡å‹æ„å»ºä¸­ç½‘ç»œçš„å‚æ•°ï¼Œç©ºé—´å¤§å°ï¼ŒMAddï¼ŒFLOPsç­‰æŒ‡æ ‡ï¼Œcount_paramså¾ˆå¥½å†™ï¼Œç„¶åå‰©ä¸‹çš„è®¡ç®—æˆ‘ä»¬äº¤ç»™ä¸¤ä¸ªç¬¬ä¸‰æ–¹çš„åº“æ¥å®ç°ï¼š`torchstat`,`thop`

```python
from torchstat import stat
stat(model,(3,224,224)) #thatâ€˜s all using it in the eval stage

```

1. ä¹Ÿå¯ä»¥ä½¿ç”¨`torchsummary`æ¥æŸ¥çœ‹å„å±‚è¾“å‡ºçš„æ•°æ®çš„ç»´åº¦æ•°ç›®

```python
from torchsummary import summary
summary(model.cuda(),input_size=(3,224,224),batch_size=1)

```

1. ç›¸åº”çš„Debugè¿˜å¯ä»¥ä½¿ç”¨`torchsnooper`è¿›è¡Œï¼šå˜é‡çš„ç±»å‹å’Œç»´åº¦è¿½è¸ªè¿™ä¸ªæ¨¡å—é€šè¿‡`@xxxx`ä¿®é¥°å™¨çš„æ–¹æ³•è°ƒç”¨åœ¨æŒ‡å®šçš„methodå‰é¢ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¾“å‡ºä¸€äº›**å‚æ•°å€¼çš„ç±»å‹**å’Œ**æ•°å€¼å˜åŒ–**çš„è¾ƒä¸ºè¯¦ç»†çš„ä¿¡æ¯ã€‚ä¸ªäººç†è§£çš„æœ€ä½³ä½¿ç”¨ç¯å¢ƒæ˜¯ï¼Œç”¨äºè°ƒè¯•æˆ–è€…ç›‘æ§**ç±»å‹ä¹‹é—´çš„é”™è¯¯**ã€‚

```python
# è¿™ä¸ªpackageå¦‚æœæ²¡è®°é”™çš„è¯å¥½åƒæ˜¯ä½¿ç”¨è£…é¥°å™¨çš„æ–¹æ³•å»è¿›è¡Œæµ‹è¯•
@...
method()

```

## 3.PyTorchåŠ è½½é¢„è®­ç»ƒæ¨¡å‹

å…·ä½“é”™è¯¯ï¼šåœ¨äºæ¨¡å‹Dictä¸­çš„Keyå’Œé¢„è®­ç»ƒmodelä¸­çš„Keyä¸å¯¹åº”ï¼Œæ— æ³•åŒ¹é…ã€‚

```json
Unexpected key(s) in state_dict: "module.features. ...".ï¼ŒExpected ".features...."

```

é—®é¢˜åˆ†æï¼š

**situation1**ï¼šå¯ä»¥çœ‹åˆ°å‰é¢å¤šäº†moduleè¿™ä¸ªstrï¼Œè¿™ä¸€èˆ¬æ˜¯ç”±äºå…¶ä¸­ä¸€æ–¹ä½¿ç”¨äº†å¤šGPUè®­ç»ƒåç›´æ¥ä¿å­˜çš„ï¼Œä¹Ÿå°±æ˜¯`DataParallel`æ¨¡å¼ä¸‹å¯¼è‡´çš„ä¸åŒ¹é…é—®é¢˜ã€‚

**solution1**ï¼š [å‚è€ƒèµ„æ–™](https://blog.csdn.net/qq_32998593/article/details/89343507)

1. loadæ¨¡å‹åå»æ‰å¤šä½™çš„å‚æ•°åœ¨äº‹å…ˆçš„æ—¶å€™å‘ç°è¿™ä¸ªæ–¹æ³•è¿˜æ˜¯å­˜åœ¨é—®é¢˜çš„ï¼Œå¹¶ä¸æ˜¯ç®€å•çš„dictå°è£…çš„ç»“æ„ï¼Œæ‰€ä»¥æ²¡æ³•è¿™æ ·ç®€å•çš„è¿›è¡Œèµ‹å€¼å¤„ç†:x:
2. ç”¨ç©ºç™½ä»£æ›¿moduleï¼Œæš‚æ—¶è¿˜æ²¡å°è¯•ï¼Œä½†æ˜¯æˆ‘è§‰å¾—ä¼šé‡åˆ°å’Œç¬¬ä¸€ä¸ªä¸€æ ·çš„é—®é¢˜:x:
3. :zap:æœ€ç®€å•çš„æ–¹æ³•ï¼šåŠ è½½æ¨¡å‹åå°†æ¨¡å‹è¿›è¡ŒDataParallelï¼Œå†è¿›è¡Œæ•°æ®çš„è½¬åŒ–ï¼Œå°†æ•°æ®è¿›è¡Œå¹¶è¡ŒåŒ–ã€‚å…·ä½“çš„æ“ä½œå¦‚ä¸‹

    ```python
    model.cuda()
    # å°†idsè®¾ç½®æˆæ‹¥æœ‰çš„GPUå³å¯ï¼Œä½†æ˜¯ä¸çŸ¥é“å•GPUçš„æƒ…å†µå¯ä¸å¯ä»¥å®ç°è¿™ç§æƒ…å†µ
    model = nn.DataParallel(model, device_ids=None)
    
    ```

**Situation2ï¼š** ä¿å­˜æ¨¡å‹æ ¼å¼ä¸º.pth.tarï¼Œæ— æ³•è½½å…¥è®­ç»ƒå¥½çš„æ¨¡å‹

**Solution2**ï¼š

åŸå› æ˜¯å› ä¸ºè¢«ä¿å­˜çš„æ¨¡å‹æ˜¯åœ¨é«˜ç‰ˆæœ¬çš„pytorchä¸‹å®ç°çš„ï¼Œä½†æ˜¯å†ä½ç‰ˆæœ¬ä¸­è¯»å–çš„æ¨¡å‹æ˜¯.pthæ ¼å¼çš„ï¼Œå°±ä¼šå‡ºç°ç‰ˆæœ¬å†²çªã€‚
è§£å†³æ–¹æ³•å¦‚ä¸‹ğŸ‘‡ï¼š

```python
# åœ¨é«˜ç‰ˆæœ¬çš„ç¯å¢ƒä¸­load modelï¼Œç„¶åå†é‡æ–°ä¿å­˜ï¼Œä¿å­˜çš„æ—¶å€™æ·»åŠ å‚æ•°ï¼Œä½¿å¾—ä¿å­˜æˆæ—§ç‰ˆæœ¬å³å¯
torch.save(checkpoint,save_path,_use_new_zipfile_serialization=False)
# DONE

```

**xxx is a zip archive(did you mean to use torch.jit.load()?)**

ä½¿ç”¨ä½ç‰ˆæœ¬çš„Torchå»Loadé«˜ç‰ˆæœ¬ï¼ˆ>1.6ï¼‰ä¿å­˜çš„æ¨¡å‹ï¼ˆ.pth.tarï¼‰é‡åˆ°çš„é—®é¢˜,

è¿™ç§é”™è¯¯ï¼Œä¸»è¦æ˜¯æ¨¡å‹çš„ç‰ˆæœ¬å†²çªã€‚

**è§£å†³åŠæ³•**ï¼šåœ¨é«˜ç‰ˆæœ¬çš„ç¯å¢ƒä¸­ï¼Œé‡æ–°loadæ¨¡å‹ï¼Œç„¶åç›´æ¥saveï¼Œåœ¨ä¿å­˜çš„æ—¶å€™æ·»åŠ å‚æ•°

`torch.save(model.state_dict(),model_path,_use_new_zipfile_serialization=False)`

å°±å¯ä»¥ä¿å­˜æˆ.pthçš„æ¨¡å‹ï¼Œä¹Ÿèƒ½åœ¨ä½ç‰ˆæœ¬çš„torchç¯å¢ƒä¸­ä½¿ç”¨äº†

## 4.some of the strides of a given numpy array are negative.

verï¼štorch1.2 è¿™ä¸ªé—®é¢˜å¯èƒ½ä¼šåœ¨åç»­çš„ç‰ˆæœ¬ä¸­è¢«ä¼˜åŒ–ã€‚

**Situation**ï¼š

https://www.cnblogs.com/devilmaycry812839668/p/13761613.html
é—®é¢˜å‡ºç°åœ¨flatæ“ä½œä¸­ï¼Œåå‘åˆ‡ç‰‡`[::-1]`ä¼šå¯¼è‡´æ•°æ®å­˜å‚¨åœ¨å†…å­˜ä¸Šä¸è¿ç»­ï¼Œåœ¨æ—§ç‰ˆæœ¬ä¸­æ— æ³•å®ç°ï¼Œå¯¹è¿™æ ·æ•°æ®è¿›è¡Œå­˜å‚¨ã€‚
**Solution1**:
æ‰€ä»¥åœ¨æ‰§å€’æ’åˆ‡ç‰‡çš„æ—¶å€™æ‰§è¡Œï¼Œ`img2 = np.ascontiguousarray(img)`  ä½¿å¾—æ•°æ®åœ¨å†…å­˜ç©ºé—´ä¸Šè¿ç»­ã€‚

**Solution2**:

æˆ–è€…æ‰§è¡Œå€’æ’åˆ‡ç‰‡çš„æ—¶å€™ï¼Œç›´æ¥`return img.copy()`

## 5.è¯»å–loaderçš„æ—¶å€™å›¾åƒçš„å¤§å°ä¸ä¸€

ä½¿ç”¨Cropå¯¹å›¾åƒè¿›è¡Œå¤„ç†çš„æ—¶å€™ï¼Œä¸æ³¨æ„çš„è¯å°±æ˜¯ä¼šå‡ºç°è¿™æ ·çš„é—®é¢˜ï¼Œå›¾åƒçš„sizeéšæœºæ”¹å˜ï¼Œå¯¼è‡´çš„è¾“å‡ºä¸ç»Ÿä¸€ã€‚ä¹Ÿå¯èƒ½æ˜¯Cropå‡½æ•°å†™çš„æœ‰é—®é¢˜ã€‚

**bug info**å¦‚ä¸‹

```bash
$ RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 182 and 360 in dimension 2

```

**Solutionï¼š**

resizeï¼Œsppï¼Œpaddingï¼Œ**adaptiveMaxPooling**ï¼ˆè‡ªé€‚åº”çš„poolingï¼Œpoolingåˆ°æŒ‡å®šçš„sizeï¼ˆchannelé™¤å¤–ï¼‰ï¼‰

## 6.bus error dataloader num_worker

åŸå› æš‚æ—¶è¿˜ä¸æ˜¯å¤ªæ¸…æ¥šï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥æŠŠnum_workerè®¾ç½®ä¸º0 æ¥è§£å†³è¿™ä¸ªé—®é¢˜.jpg

## 7.bus errorï¼šinsufficient shared memoryï¼ˆshmï¼‰

è¿™ç§åŸå› é€šå¸¸ä¼šåœ¨dockerç¯å¢ƒä¸­å‡ºç°ï¼Œç”±äºæœªæŒ‡å®šshmå®¹é‡å¤§å°ï¼Œæ¯”å¦‚`ipc=host`ä¹‹ç±»çš„å‘½ä»¤ï¼Œå°±ä¼šå¯¼è‡´dockerçš„shmåªæœ‰64mï¼Œäºæ˜¯åœ¨è¿è¡Œçš„æ—¶å€™å°±ä¼šå‡ºé—®é¢˜ã€‚è¿™ç§æƒ…å†µä¸‹**åªèƒ½é‡æ–°run docker**ï¼ˆç›®å‰åªæ‰¾åˆ°äº†è¿™ä¸ªæ–¹æ³•ï¼‰ã€‚

å¦‚æœè¦å¦¥åçš„è¯ï¼Œå°±åªèƒ½**è¯•ç€å‡å°batch_size**ã€‚ä½†æ˜¯éšç€æ¨¡å‹çš„è®¾è®¡ä¸Šï¼Œè¿™å…¶å®ä¸æ˜¯ä¸€ä¸ªå¯ä»¥é€ƒé¿çš„é—®é¢˜ï¼Œä¹Ÿä¼šå¢åŠ è«é¡»æœ‰çš„å…¶ä»–æˆæœ¬ï¼Œæ‰€ä»¥ã€‚

## 8.è®­ç»ƒè¿‡ç¨‹ä¸­Cacheå’ŒMemoryçš„å ç”¨é€æ¸å‡é«˜

ä¸»è¦çš„ä½“ç°æ˜¯ï¼š**é€æ¸å‡é«˜**è¿™ä¸€ç‚¹ï¼Œè€Œä¸æ˜¯ç¨³å®šçš„æƒ…å†µï¼›

æœ‰ç‚¹ç„å­¦ï¼Œä½†æ˜¯åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åœ¨æ¯ä¸ªiterationç»“æŸçš„æ—¶å€™ä½¿ç”¨æ¸…æ¥šæ˜¾å­˜çš„å‡½æ•°ï¼Œç«Ÿç„¶å°±èƒ½è¿›è¡Œæ§åˆ¶äº†ï¼Œè™½ç„¶æˆ‘ä¸çŸ¥é“ä¸ºå•¥æ¸…æ¥šæ˜¾å­˜çš„å‡½æ•°ä¼šé¡ºä¾¿è¿å†…å­˜ä¸­çš„cacheä¹Ÿä¸€èµ·æ¸…é™¤äº†ï¼Œä½†æ˜¯å°±æ˜¯ï¼Œå­¦ã€‚

```python
torch.cuda.empty_cache()
```

## 9.æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œç®—æ³•æ²¡æœ‰å­¦ä¹ æ•ˆæœ

æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œåˆ†æå¯èƒ½å‡ºç°å­˜åœ¨çš„é—®é¢˜ï¼š

- æŸä¸€éƒ¨åˆ†çš„å­¦ä¹ å‚æ•°å¯èƒ½çš„lrè¿‡é«˜ï¼Œæƒé‡è¿‡é«˜ï¼Œå¯¼è‡´è¯¯å·®å¿«é€Ÿä¼ æ’­ã€‚
- é—®é¢˜çš„å¤æ‚åº¦è¿‡é«˜ï¼Œç®—æ³•overpoweräº†æŠŠã€‚

é’ˆå¯¹äºç¬¬ä¸€ç‚¹çš„è¯ï¼Œæˆ‘ä»¬å‚è€ƒå·¥ç¨‹ç¬”è®°ä¸­çš„å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥å³å¯ã€‚

å¦‚æœæ˜¯é—®é¢˜çš„å¤æ‚åº¦è¿‡é«˜ï¼Œé‚£ä¹ˆå¯èƒ½æ˜¯é—®é¢˜å¯¹äºæˆ‘ä»¬çš„æ¨¡å‹æ¥è¯´å·²ç»overpowerçš„ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦å»åŠ æ·±ç½‘ç»œçš„å±‚æ•°ï¼Œæˆ–è€…å¯¹ç½‘ç»œè¿›è¡Œè¿›ä¸€æ­¥çš„è®¾è®¡å’Œå¯¹æ•°æ®çš„åˆ†æé—®é¢˜ã€‚

## 10.ç±»å‹è½¬æ¢é—®é¢˜æ±‡æ€»

1. æ¯”å¦‚`scatter_`éœ€è¦å°†æ•°æ®ä»int32çš„æ ¼å¼è½¬æ¢æˆint64ï¼Œæˆ‘ä»¬è¦æŒæ¡ä¸€ä¸‹åœ¨Pytorchä¸­è¿›è¡Œæ•°æ®ç±»å‹è½¬æ¢çš„æŠ€å·§ã€‚
2. **Expected object of scalar type Float but got scalar type Double for argument #2 'target'** æ•°æ®ç±»å‹ä¸åŒ¹é…ï¼Œä¸€ä¸ªæ˜¯np.float32,å¦ä¸€ä¸ªæ˜¯64
å‚è€ƒè§£å†³æ–¹æ¡ˆï¼š[é‡è¦](https://stackoverflow.com/questions/56741087/how-to-fix-runtimeerror-expected-object-of-scalar-type-float-but-got-scalar-typ)
3. **Expected object of scalar type Long but got scalar type Float for argument**
å¸Œæœ›å¾—åˆ°çš„æ˜¯Longå‹æ ‡é‡æ•°æ®ï¼Œä½†æ˜¯å¾—åˆ°äº†Floatå‹çš„æ•°æ®ï¼ˆå®é™…ä¸Šå¯èƒ½æ˜¯æˆ‘ä»¬è¿›è¡Œæµ‹è¯•çš„æ—¶å€™ä½¿ç”¨äº†å°æ•°å¸¦æ¥çš„ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹Ÿèƒ½å°†å…¶è½¬åŒ–å°±æ˜¯äº†ï¼‰

    ```python
    Longtensor()
    type(torch.longtensor)

    ```

4. **RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.DoubleTensor) should be the same**
**RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same**é—®é¢˜å®é™…ä¸Šéƒ½æ˜¯å’Œæƒé‡çš„æ•°æ®ç±»å‹ä¸åŒ¹é…ï¼Œéœ€è¦å°†å­—èŠ‚å‹æˆ–è€…æ˜¯FLoatå‹å‘Weightçš„æ•°æ®ç±»å‹è½¬æ¢ï¼Œä½†æ˜¯å¯èƒ½è¿™é‡Œçš„é—®é¢˜å®é™…ä¸Šå‡ºç°åœ¨å°±æ˜¯æˆ‘ä»¬å¯¼å…¥çš„æ•°æ®ç±»å‹æ˜¯ä¸æ­£ç¡®çš„ã€‚è¿˜æ˜¯ä½¿ç”¨`type()`å‘½ä»¤æ¥è¿›è¡Œæ•°æ®ç±»å‹çš„è½¬æ¢ï¼Œä½†æ˜¯å…³é”®è¿˜æ˜¯ï¼š**æ£€æŸ¥è¾“å…¥æ•°æ®çš„ç±»å‹ä»¥åŠæ•°å€¼èŒƒå›´ï¼ŒåŒæ—¶çœ‹çœ‹åœ¨è¿›è¡Œdataloaderçš„æ—¶å€™æœ‰æ²¡æœ‰æŒ‡å®što_tensorçš„å˜æ¢ç­‰ç­‰**

[å‚è€ƒèµ„æ–™é“¾æ¥](https://www.jianshu.com/p/75dff8e7ed18)

**è¿›è¡Œæ•°æ®è½¬æ¢çš„å‡ ç§æ–¹å¼**

1. ä½¿ç”¨å‡½æ•°`tensor1.type_as(tensor2)`å°†1çš„æ•°æ®ç±»å‹è½¬æ¢æˆ2çš„æ•°æ®ç±»å‹ã€‚

    ```python
    tensor_1 = torch.FloatTensor(5)
    tensor_2 = torch.IntTensor([10, 20])
    tensor_1 = tensor_1.type_as(tensor_2)

    ```

2. `tensor.type(torch.IntTensor)`
3. `tensor.long()`,`tensor.char()`,`tensor.int()`,`tensor.byte()`,`tensor.double()`
4. `tenosr.to(torch.long)`

## 11.æ•°æ®ç»´åº¦ä¸å¯¹åº”é—®é¢˜æ±‡æ€»

1. **multi-target not supported at**é—®é¢˜å®é™…ä¸Šå¯ä»¥ç¿»è¯‘æˆï¼šç»´åº¦ä¸Šå’Œäº¤å‰ç†µæŸå¤±å‡½æ•°çš„éœ€æ±‚ä¸å¯¹åº”ã€‚åœ¨ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°çš„æ—¶å€™ï¼Œtargetçš„å½¢çŠ¶åº”è¯¥æ˜¯å’Œlabelçš„å½¢çŠ¶ä¸€è‡´æˆ–è€…æ˜¯åªæœ‰batchsizeè¿™ä¸€ä¸ªç»´åº¦çš„ã€‚å¦‚æœtargetæ˜¯è¿™æ ·çš„ã€batchszieï¼Œ1ã€‘å°±ä¼šå‡ºç°ä¸Šè¿°çš„é”™è¯¯

    ```python
    ä½¿ç”¨squeezeï¼ˆï¼‰å‡½æ•°é™ä½ç»´åº¦
    ```

## 12.å–å‡ºå…·ä½“æ•°å€¼æ—¶å€™çš„é—®é¢˜

1. **RuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy()**å¯¹äºè¾“å‡ºçš„ç»“æœè¦è½¬æ¢æˆå…·ä½“çš„æ•°å€¼çš„æ—¶å€™ï¼Œå¦‚æœæˆ‘ä»¬åç»­è¿˜éœ€è¦è¿™ä¸ªæ•°å€¼çš„æ¢¯åº¦ï¼Œå°±ä¸èƒ½è½¬æ¢åˆ°`cpu`åå†è½¬æ¢åˆ°`numpy`,å°±å¥½æ¯”è¯´ï¼Œæˆ‘ä»¬è¦å–å‡ºLossçš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨item()å–å‡ºå…·ä½“çš„æ•°å€¼ï¼Œè€Œä¸éœ€è¦è½¬åˆ°CPU[ä¸Š](#)

## 13.CPUå ç”¨99%

é—®é¢˜æè¿°ï¼šä½¿ç”¨torchè‡ªå¸¦çš„datasetä¸­çš„cifar10çš„æ—¶å€™ï¼Œåœ¨æ¯ä¸ªepochç»“æŸçš„æ—¶å€™ï¼ŒCPUå ç”¨ç‡é«˜è¾¾99%ï¼Œå¹¶ä¸éšç€num_workderè€Œæ”¹å˜ï¼Œé—®é¢˜å¯èƒ½ç”±äºpytorchå¼€è¾Ÿäº†å¤ªå¤šçš„çº¿ç¨‹

[windows10ä¸‹pytorchçš„GPUåˆ©ç”¨ç‡ä½ï¼Œå ç”¨ç‡ä½_stay_zezoçš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/stay_zezo/article/details/107809409)

å¯èƒ½æ˜¯ç”±äºGPUè¿ç®—å¤ªå¿«äº†ï¼Œå¯ç”¨äº†å¤šçº¿ç¨‹è¿›è¡ŒåŠ è½½æ•°æ®ï¼Œè¿™ç§æ—¶å€™å¯ç”¨`pin_memory=true` èƒ½èµ·åˆ°ä¸€å®šçš„ä½œç”¨æŠŠï¼ŒåŠ å¿«ä¸€ç‚¹æ•°æ®è¯»å–ã€‚

æœ€ç»ˆè§£å†³æ–¹æ¡ˆ ï¼š`pin-memory=false` åæ­£åŸå› å¾ˆç¥å¥‡ï¼Œä½†æ˜¯æœ€ç»ˆå°±æ˜¯å› ä¸ºè¿™ä¸ªè§£å†³çš„ï¼Œå¯èƒ½æ˜¯å› ä¸ºmemoryè¶…äº†ï¼Œæ‰€ä»¥æ¯æ¬¡éƒ½éœ€è¦é‡æ–°empty_cache é‡æ–°è£…è¿›é¡µï¼Œæ‰€ä»¥åè€ŒåŠ é‡äº†CPUçš„è´Ÿæ‹…

## 14. é¢„æµ‹å€¼å…¨ä¸º0ï¼Œæ¨¡å‹æ”¶æ•›åˆ°å¥‡æ€ªçš„åœ°æ–¹ï¼ŒæŸå¤±ä¿æŒä¸€è‡´ï¼ˆå…¨å‡ç­‰ï¼‰

è¿™ç§æƒ…å†µé€šå¸¸æ˜¯ç”±äºæ¨¡å‹è®¾è®¡ä¸­å­˜åœ¨ä¸€ç‚¹é—®é¢˜ï¼š

æ¯”å¦‚è¿™æ¬¡æ˜¯ç”±äºæ¨¡å‹ä¸­fcåé¢æ·»åŠ äº†reluï¼Œè¿™æ ·å¯¼è‡´è¾“å‡ºçš„è´Ÿå€¼å…¨è¢«æŠ‘åˆ¶äº†ï¼Œå¯¼è‡´å­¦ä¹ å‡ºç°äº†ä¸¥é‡çš„é”™è¯¯åæœã€‚

## 15.æ¨¡å‹éƒ¨åˆ†ï¼š è®­ç»ƒä¸­æ¨¡å‹å‡†ç¡®ç‡ä¸ä¸Šå‡

ç”±äºæ¡†æ¶å·²ç»éªŒè¯è¿‡æ˜¯å¯ä»¥è¿›è¡Œæ­£å¸¸è®­ç»ƒçš„ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹å‡ºç°æ¨¡å‹çš„å‡†ç¡®ç‡ä¸ä¸Šå‡å¯èƒ½æ˜¯ç”±äºæ¨¡å‹æœ¬èº«è®¾è®¡ï¼ˆå†…éƒ¨ä»£ç ç¼–å†™ï¼‰ä¸Šçš„é—®é¢˜ã€‚

## 16. On entry to SGEMM parameter number 8 had an illegal value

Tracing failed sanity checks!
Graphs differed across invocations!

fcçš„é—®é¢˜ï¼Œè¾“å…¥fcå’Œå¯¹åº”çš„ç½‘ç»œè¾“å…¥å±‚ä¸ä¸€è‡´ï¼Œæ£€æŸ¥é˜¶æ®µæ•°ç›®å’Œfeatureè¾“å‡ºçš„ç‰¹å¾ç»´åº¦



## 17. CUDA error: device-side assert triggered CUDA kernel errors might be asynchronously reported at some other API call

è¿™ä¸ªé—®é¢˜çš„å‡ºç°çš„æ ¹æœ¬åŸå› åœ¨äºï¼š

ç»´åº¦ä¸åŒ¹é…ï¼šæ ‡ç­¾çš„dimension è¶…å‡ºäº†å…¨è¿æ¥å±‚æœ€åè¾“å‡ºçš„dimensionï¼Œè¿™ä¸€éƒ¨åˆ†é”™è¯¯çš„è§¦å‘ï¼Œå’ŒLossçš„è®¡ç®—ï¼ŒAccçš„è®¡ç®—ï¼Œæœ‰ç€å¼ºçƒˆçš„ç›¸å…³å…³ç³»ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒç›¸å…³çš„éªŒè¯å’Œè®­ç»ƒç¯èŠ‚ï¼Œéœ€è¦ä¿æŒè®­ç»ƒæ•°æ®é›†å’ŒéªŒè¯æ•°æ®é›†åœ¨ç±»åˆ«æ•°ç›®ä¸Šçš„ä¸€è‡´æ€§ï¼Œè€Œåœ¨æˆ‘ä»¬éœ€è¦å¯¹æ•°æ®é›†å¤–çš„æ•°æ®è¿›è¡Œæµ‹è¯•çš„æ—¶å€™ï¼Œæˆ‘ä»¬é¿å…è¿›è¡ŒLossçš„è®¡ç®—ï¼Œåœ¨å¯¹Accè¿›è¡Œè®¡ç®—çš„æ—¶å€™ï¼Œä¹Ÿå°½é‡é¿å…Torchä¸­çš„è‡ªæœ‰åº“ï¼Œé¿å…äº§ç”Ÿè¯¥ç±»çš„é—®é¢˜/

## RuntimeError the derivative for target is not implemented
é—®é¢˜é€šå¸¸å‡ºç°åœ¨æŸå¤±è®¡ç®—çš„è¿‡ç¨‹ä¸­ï¼Œè¿™ä¸ªé”™è¯¯æ˜¯ç”±äºæˆ‘ä»¬åœ¨æŸå¤±ä¸­çš„ç¬¬äºŒé¡¹ `targets`ä¸åº”è¯¥æœ‰æ¢¯åº¦ï¼Œä½†æ˜¯åœ¨è¿™ä¸ªåœ°æ–¹å´å­˜åœ¨æ¢¯åº¦å¯¼è‡´çš„.

åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»…ä»…å–å‡º `tensor`çš„`data`æˆ–è€…ä½¿ç”¨`detach`and`copy`æ¥è¿›è¡Œæ•°å€¼çš„ä¼ é€’

##  Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment

è¯¥é”™è¯¯æ˜¯ç”±deepcopyå’Œrequire_grad, require_fnåŒæ—¶æ„æˆ, å¦‚æœæˆ‘ä»¬å¯¹ä¸€ä¸ªéœ€è¦è®¡ç®—æ¢¯åº¦çš„éå¶å­èŠ‚ç‚¹è¿›è¡Œdeepcopyå°±ä¼šè§¦å‘è¿™ä¸ªé”™è¯¯ã€‚

å¦‚æœæˆ‘ä»¬éœ€è¦å¯¹è¿™ä¸ªæ•°æ®è¿›è¡Œå­˜å‚¨çš„è¯ï¼Œæˆ‘ä»¬å¯ä»¥æ‰§è¡Œ
```python
save = copy.deepcopy(feature.data.cpu().numpy())
```